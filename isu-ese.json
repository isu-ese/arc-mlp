[
  {"id":"gareyComputersIntractabilityGuide1979","type":"book","title":"Computers and intractability: A  guide to the theory of NP-completeness","collection-title":"Series of books in the mathematical sciences","publisher":"W.H. Freeman","source":"EBSCOhost","archive_location":"Main Book Collection (2nd Floor) QA76.6","abstract":"Summary: \"Shows how to recognize NP-complete problems and offers proactical suggestions for dealing with them effectively. The book covers the basic theory of NP-completeness, provides an overview of alternative directions for further research, and contains and extensive list of NP-complete and NP-hard problems, with more than 300 main entries and several times as many results in total. [This book] is suitable as a supplement to courses in algorithm design, computational complexity, operations research, or combinatorial mathematics, and as a text for seminars on approximation algorithms or computational complexity. It provides not only a valuable source of information for students but also an essential reference work for professionals in computer science\"--Back cover.","ISBN":"978-0-7167-1045-5","title-short":"Computers and intractability","author":[{"family":"Garey","given":"Michael R."},{"family":"Johnson","given":"David S."}],"issued":{"date-parts":[[1979]]}},
  {"id":"mushtaqMultilingualSourceCode2017","type":"article-journal","title":"Multilingual Source Code Analysis: A Systematic Literature Review","container-title":"IEEE Access","page":"11307-11336","volume":"5","source":"IEEE Xplore","abstract":"Contemporary software applications are developed using cross-language artifacts, which are interdependent with each other. The source code analysis of these applications requires the extraction and examination of artifacts, which are build using multiple programming languages along with their dependencies. A large number of studies presented on multilingual source code analysis and its applications in the last one and half decade. The objective of this systematic literature review (SLR) is to summarize state of the art and prominent areas for future research. This SLR is based on different techniques, tools, and methodologies to analyze multilingual source code applications. We finalized 56 multi-discipline published papers relevant to multilingual source code analysis and its applications out of 3820 papers, filtered through multi-stage search criterion. Based on our findings, we highlight research gaps and challenges in the field of multilingual applications. The research findings are presented in the form of research problems, research contributions, challenges, and future prospects. We identified 46 research issues and requirements for analyzing multilingual applications and grouped them in 13 different software engineering domains. We examined the research contributions and mapped them with individual research problems. We presented the research contributions in the form of tools techniques and approaches that are presented in the form of research models, platforms, frameworks, prototype models, and case studies. Every research has its limitations or prospects for future research. We highlighted the limitations and future perspectives and grouped them in various software engineering domains. Most of the research trends and potential research areas are identified in static source code analysis, program comprehension, refactoring, reverse engineering, detection, and traceability of cross-language links, code coverage, security analysis, cross-language parsing, and abstraction of source code models.","DOI":"10.1109/ACCESS.2017.2710421","ISSN":"2169-3536","title-short":"Multilingual Source Code Analysis","author":[{"family":"Mushtaq","given":"Z."},{"family":"Rasool","given":"G."},{"family":"Shehzad","given":"B."}],"issued":{"date-parts":[[2017]]}},
  {"id":"durandEfficientAlgorithmSimilarity1999","type":"article-journal","title":"An efficient algorithm for similarity analysis of molecules","container-title":"Internet Journal of Chemistry","page":"1–16","volume":"2","issue":"17","source":"Google Scholar","author":[{"family":"Durand","given":"Paul J."},{"family":"Pasari","given":"Rohit"},{"family":"Baker","given":"Johnnie W."},{"family":"Tsai","given":"Chun-che"}],"issued":{"date-parts":[[1999]]}},
  {"id":"wellingPerformanceAnalysisMaximal2011","type":"paper-conference","title":"A Performance Analysis on Maximal Common Subgraph Algorithms","source":"Semantic Scholar","abstract":"Graphs can be used as a tool to determine similarity between structured objects. The maximal common subgraph of two graphs G and H is the largest graph in terms of edges that is isomorphic to a subgraph of G and H. Finding the maximal common subgraph is an NP-complete problem. It is useful in many areas like (bio)chemistry, file versioning and artificial intelligence. There are many papers that evaluate algorithms for finding maximal common induced subgraphs, but little research has been done on the maximal common subgraph that is not an induced subgraph. We have implemented and benchmarked two maximal common (not induced) subgraph algorithms: a backtrack search algorithm (McGregor), and an algorithm that transforms the maximal common subgraph problem to the largest clique problem (Koch). We created generators for randomly connected and mesh structured graphs, these generators have been used to create a database of graph pairs to benchmark the two algorithms. The results of our benchmark have shown that in most cases Koch is more efficient, because after creating the edge product graph needed for the clique detection. The actual clique detection is a relatively simple search.","author":[{"family":"Welling","given":"Ruud"}],"issued":{"date-parts":[[2011]]}},
  {"id":"conteChallengingComplexityMaximum2007","type":"article-journal","title":"Challenging Complexity of Maximum Common Subgraph Detection Algorithms: A Performance Analysis of Three Algorithms on a Wide Database of Graphs","container-title":"J. Graph Algorithms Appl.","page":"99-143","volume":"11","source":"Semantic Scholar","abstract":"Graphs are an extremely general and powerful data structure. In pattern recognition and computer vision, graphs are used to represent patterns to be recognized or classified. Detection of maximum common subgraph (MCS) is useful for matching, comparing and evaluate the similarity of patterns. MCS is a well known NP-complete problem for which optimal and suboptimal algorithms are known from the literature. Nevertheless, until now no effort has been done for characterizing their performance. The lack of a large database of graphs makes the task of comparing the performance of different graph matching algorithms difficult, and often the selection of an algorithm is made on the basis of a few experimental results available. In this paper, three optimal and well-known algorithms for maximum common subgraph detection are described. Moreover a large database containing various categories of pairs of graphs (e.g. random graphs, meshes, bounded valence graphs), is presented, and the performance of the three algorithms is evaluated on this database. Article Type Communicated by Submitted Revised Regular Paper U. Brandes September 2005 January 2007 D. Conte et al., Maximum Common Subgraph, JGAA, 11(1) 99–143 (2007) 100","DOI":"10.7155/jgaa.00139","title-short":"Challenging Complexity of Maximum Common Subgraph Detection Algorithms","author":[{"family":"Conte","given":"Donatello"},{"family":"Foggia","given":"Pasquale"},{"family":"Vento","given":"Mario"}],"issued":{"date-parts":[[2007]]}},
  {"id":"conteComparisonThreeMaximum2003","type":"paper-conference","title":"A Comparison of Three Maximum Common Subgraph Algorithms on a Large Database of Labeled Graphs","container-title":"Proceedings of the 4th IAPR International Conference on Graph Based Representations in Pattern Recognition","collection-title":"GbRPR'03","publisher":"Springer-Verlag","page":"130–141","source":"ACM Digital Library","abstract":"A graph g is called a maximum common subgraph of two graphs, g1 and g2, if there exists no other common subgraph of g1 and g2 that has more nodes than g. For the maximum common subgraph problem, exact and inexact algorithms are known from the literature. Nevertheless, until now no effort has been done for characterizing their performance, mainly for the lack of a large database of graphs. In this paper, three exact and well-known algorithms for maximum common subgraph detection are described. Moreover, a large database containing various categories of pairs of graphs (e.g. randomly connected graphs, meshes, bounded valence graphs...), having a maximum common subgraph of at least two nodes, is presented, and the performance of the three algorithms is evaluated on this database.","URL":"http://dl.acm.org/citation.cfm?id=1757868.1757884","ISBN":"978-3-540-40452-1","author":[{"family":"Conte","given":"D."},{"family":"Guidobaldi","given":"C."},{"family":"Sansone","given":"C."}],"issued":{"date-parts":[[2003]]},"accessed":{"date-parts":[[2019,5,10]]},"publisher-place":"Berlin, Heidelberg","event-place":"York, UK"},
  {"id":"raymondMaximumCommonSubgraph","type":"article-journal","title":"Maximum common subgraph isomorphism algorithms for the matching of chemical structures","page":"13","source":"Zotero","abstract":"The maximum common subgraph (MCS) problem has become increasingly important in those aspects of chemoinformatics that involve the matching of 2D or 3D chemical structures. This paper provides a classiﬁcation and a review of the many MCS algorithms, both exact and approximate, that have been described in the literature, and makes recommendations regarding their applicability to typical chemoinformatics tasks.","language":"en","author":[{"family":"Raymond","given":"John W"},{"family":"Willett","given":"Peter"}]},
  {"id":"tomitaWorstcaseTimeComplexity2006","type":"article-journal","title":"The worst-case time complexity for generating all maximal cliques and computational experiments","container-title":"Theoretical Computer Science","collection-title":"Computing and Combinatorics","page":"28-42","volume":"363","issue":"1","source":"ScienceDirect","abstract":"We present a depth-first search algorithm for generating all maximal cliques of an undirected graph, in which pruning methods are employed as in the Bron–Kerbosch algorithm. All the maximal cliques generated are output in a tree-like form. Subsequently, we prove that its worst-case time complexity is O(3n/3) for an n-vertex graph. This is optimal as a function of n, since there exist up to 3n/3 maximal cliques in an n-vertex graph. The algorithm is also demonstrated to run very fast in practice by computational experiments.","URL":"http://www.sciencedirect.com/science/article/pii/S0304397506003586","DOI":"10.1016/j.tcs.2006.06.015","ISSN":"0304-3975","author":[{"family":"Tomita","given":"Etsuji"},{"family":"Tanaka","given":"Akira"},{"family":"Takahashi","given":"Haruhisa"}],"issued":{"date-parts":[[2006,10,25]]},"accessed":{"date-parts":[[2019,5,9]]},"container-title-short":"Theoretical Computer Science"},
  {"id":"bettenburgWhatMakesGood2008","type":"paper-conference","title":"What makes a good bug report?","container-title":"Proceedings of the 16th ACM SIGSOFT International Symposium on Foundations of software engineering","publisher":"ACM","page":"308–318","source":"Google Scholar","author":[{"family":"Bettenburg","given":"Nicolas"},{"family":"Just","given":"Sascha"},{"family":"Schröter","given":"Adrian"},{"family":"Weiss","given":"Cathrin"},{"family":"Premraj","given":"Rahul"},{"family":"Zimmermann","given":"Thomas"}],"issued":{"date-parts":[[2008]]}},
  {"id":"bastaniSynthesizingProgramInput2017","type":"paper-conference","title":"Synthesizing program input grammars","container-title":"Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation  - PLDI 2017","publisher":"ACM Press","page":"95-110","source":"DOI.org (Crossref)","event":"the 38th ACM SIGPLAN Conference","abstract":"We present an algorithm for synthesizing a context-free grammar encoding the language of valid program inputs from a set of input examples and blackbox access to the program. Our algorithm addresses shortcomings of existing grammar inference algorithms, which both severely overgeneralize and are prohibitively slow. Our implementation, GLADE, leverages the grammar synthesized by our algorithm to fuzz test programs with structured inputs. We show that GLADE substantially increases the incremental coverage on valid inputs compared to two baseline fuzzers.","URL":"http://dl.acm.org/citation.cfm?doid=3062341.3062349","DOI":"10.1145/3062341.3062349","ISBN":"978-1-4503-4988-8","language":"en","author":[{"family":"Bastani","given":"Osbert"},{"family":"Sharma","given":"Rahul"},{"family":"Aiken","given":"Alex"},{"family":"Liang","given":"Percy"}],"issued":{"date-parts":[[2017]]},"accessed":{"date-parts":[[2019,4,18]]},"publisher-place":"Barcelona, Spain"},
  {"id":"klintEngineeringDisciplineGrammarware2005","type":"article-journal","title":"Toward an engineering discipline for grammarware","container-title":"ACM Transactions on Software Engineering and Methodology","page":"331-380","volume":"14","issue":"3","source":"DOI.org (Crossref)","URL":"http://portal.acm.org/citation.cfm?doid=1072997.1073000","DOI":"10.1145/1072997.1073000","ISSN":"1049331X","language":"en","author":[{"family":"Klint","given":"Paul"},{"family":"Lämmel","given":"Ralf"},{"family":"Verhoef","given":"Chris"}],"issued":{"date-parts":[[2005,7,1]]},"accessed":{"date-parts":[[2019,4,18]]}},
  {"id":"goloveshkinTolerantParsingSpecial2018","type":"article-journal","title":"Tolerant parsing with a special kind of «Any» symbol: the algorithm and practical application","container-title":"Proceedings of the Institute for System Programming of the RAS","page":"7-28","volume":"30","issue":"4","source":"DOI.org (Crossref)","abstract":"Tolerant parsing is a form of syntax analysis aimed at capturing the structure of certain points of interest presented in a source code. While these points should be welldescribed in the corresponding language grammar, other parts of the program are allowed to be not presented in the grammar or to be described coarse-grained, thereby parser remains tolerant to the possible inconsistencies in the irrelevant area. Island grammars are one of the basic tolerant parsing techniques. “Island” is used as the relevant code alias, while the irrelevant code is called “water”. In the paper, a modified LL(1) parsing algorithm with built-in “Any” symbol processing is described. The “Any” symbol matches implicitly defined token sequences. The use of the algorithm for island grammars allows one to reduce irrelevant code description as well as to simplify patterns for relevant code matching. Our “Any” implementation is more accurate and less restrictive in comparison with the closest analogues implemented in Coco/R and LightParse parser generators. It also has potentially lower overhead than the “bounded seas” concept implemented in PetitParser. As shown in the experimental section, the tolerant parser generated by the C# island grammar is proven to be applicable for large-scale software projects analysis.","URL":"http://www.ispras.ru/en/proceedings/isp_30_2018_4/isp_30_2018_4_7/","DOI":"10.15514/ISPRAS-2018-30(4)-1","ISSN":"20798156, 22206426","title-short":"Tolerant parsing with a special kind of «Any» symbol","language":"en","author":[{"family":"Goloveshkin","given":"A.V."},{"family":"Mikhalkovich","given":"S.S."}],"issued":{"date-parts":[[2018]]},"accessed":{"date-parts":[[2019,4,19]]}},
  {"id":"shangTamingVerificationHardness2008","type":"article-journal","title":"Taming verification hardness: an efficient algorithm for testing subgraph isomorphism","container-title":"Proceedings of the VLDB Endowment","page":"364–375","volume":"1","issue":"1","source":"Google Scholar","title-short":"Taming verification hardness","author":[{"family":"Shang","given":"Haichuan"},{"family":"Zhang","given":"Ying"},{"family":"Lin","given":"Xuemin"},{"family":"Yu","given":"Jeffrey Xu"}],"issued":{"date-parts":[[2008]]}},
  {"id":"synytskyyRobustMultilingualParsing2003","type":"paper-conference","title":"Robust multilingual parsing using island grammars","container-title":"Proceedings of the 2003 conference of the Centre for Advanced Studies on Collaborative research","publisher":"IBM Press","page":"266–278","source":"Google Scholar","author":[{"family":"Synytskyy","given":"Nikita"},{"family":"Cordy","given":"James R."},{"family":"Dean","given":"Thomas R."}],"issued":{"date-parts":[[2003]]}},
  {"id":"grindleyIdentificationTertiaryStructure1993","type":"article-journal","title":"Identification of tertiary structure resemblance in proteins using a maximal common subgraph isomorphism algorithm","container-title":"Journal of molecular biology","page":"707–721","volume":"229","issue":"3","source":"Google Scholar","author":[{"family":"Grindley","given":"Helen M."},{"family":"Artymiuk","given":"Peter J."},{"family":"Rice","given":"David W."},{"family":"Willett","given":"Peter"}],"issued":{"date-parts":[[1993]]}},
  {"id":"bacchelliExtractingStructuredData2011","type":"paper-conference","title":"Extracting structured data from natural language documents with island parsing","container-title":"Automated Software Engineering (ASE), 2011 26th IEEE/ACM International Conference on","publisher":"IEEE","page":"476–479","source":"Google Scholar","author":[{"family":"Bacchelli","given":"Alberto"},{"family":"Cleve","given":"Anthony"},{"family":"Lanza","given":"Michele"},{"family":"Mocci","given":"Andrea"}],"issued":{"date-parts":[[2011]]}},
  {"id":"streinCrosslanguageProgramAnalysis2006","type":"paper-conference","title":"Cross-language program analysis and refactoring","container-title":"2006 Sixth IEEE International Workshop on Source Code Analysis and Manipulation","publisher":"IEEE","page":"207–216","source":"Google Scholar","author":[{"family":"Strein","given":"Dennis"},{"family":"Kratz","given":"Hans"},{"family":"Lowe","given":"Welf"}],"issued":{"date-parts":[[2006]]}},
  {"id":"reinhardwilhelmCompilerDesign1995","type":"book","title":"Compiler Design","publisher":"Addison-Wesley","number-of-pages":"606","ISBN":"0-201-42290-5","author":[{"family":"Reinhard Wilhelm","given":"Dieter Maurer"}],"issued":{"date-parts":[[1995,1,1]]},"publisher-place":"Boston, United States"},
  {"id":"deursenBuildingDocumentationGenerators1999","type":"paper-conference","title":"Building documentation generators","container-title":"Proceedings IEEE International Conference on Software Maintenance - 1999 (ICSM'99). 'Software Maintenance for Business Change' (Cat. No.99CB36360)","page":"40-49","source":"IEEE Xplore","event":"Proceedings IEEE International Conference on Software Maintenance - 1999 (ICSM'99). 'Software Maintenance for Business Change' (Cat. No.99CB36360)","abstract":"In order to maintain the consistency between sources and documentation, while at the same time providing documentation at the design level, it is necessary to generate documentation from sources in such a way that it can be integrated with hand-written documentation. In order to simplify the construction of documentation generators, we introduce island grammars, which only define those syntactic structures needed for (re)documentation purposes. We explain how they can be used to obtain various forms of documentation, such as data dependency diagrams for mainframe batch jobs. Moreover, we discuss how the derived information can be made available via a hypertext structure. We conclude with an industrial case study in which a 600,000 LOC COBOL legacy system is redocumented using the techniques presented in the paper.","DOI":"10.1109/ICSM.1999.792497","author":[{"family":"Deursen","given":"A. Van"},{"family":"Kuipers","given":"T."}],"issued":{"date-parts":[[1999,8]]}},
  {"id":"ullmannAlgorithmSubgraphIsomorphism1976","type":"article-journal","title":"An algorithm for subgraph isomorphism","container-title":"Journal of the ACM (JACM)","page":"31–42","volume":"23","issue":"1","source":"Google Scholar","author":[{"family":"Ullmann","given":"Julian R."}],"issued":{"date-parts":[[1976]]}},
  {"id":"messmerNewAlgorithmErrortolerant1998","type":"article-journal","title":"A new algorithm for error-tolerant subgraph isomorphism detection","container-title":"IEEE Transactions on Pattern Analysis and Machine Intelligence","page":"493–504","volume":"20","issue":"5","source":"Google Scholar","author":[{"family":"Messmer","given":"Bruno T."},{"family":"Bunke","given":"Horst"}],"issued":{"date-parts":[[1998]]}},
  {"id":"bunkeComparisonAlgorithmsMaximum2002","type":"paper-conference","title":"A comparison of algorithms for maximum common subgraph on randomly connected graphs","container-title":"Joint IAPR International Workshops on Statistical Techniques in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition (SSPR)","publisher":"Springer","page":"123–132","source":"Google Scholar","author":[{"family":"Bunke","given":"Horst"},{"family":"Foggia","given":"Pasquale"},{"family":"Guidobaldi","given":"Corrado"},{"family":"Sansone","given":"Carlo"},{"family":"Vento","given":"Mario"}],"issued":{"date-parts":[[2002]]}},
  {"id":"cordellaSubGraphIsomorphism2004","type":"article-journal","title":"A (sub) graph isomorphism algorithm for matching large graphs","container-title":"IEEE transactions on pattern analysis and machine intelligence","page":"1367–1372","volume":"26","issue":"10","source":"Google Scholar","author":[{"family":"Cordella","given":"Luigi P."},{"family":"Foggia","given":"Pasquale"},{"family":"Sansone","given":"Carlo"},{"family":"Vento","given":"Mario"}],"issued":{"date-parts":[[2004]]}},
  {"id":"eppsteinSubgraphIsomorphismPlanar2002","type":"chapter","title":"Subgraph isomorphism in planar graphs and related problems","container-title":"Graph Algorithms And Applications I","publisher":"World Scientific","page":"283–309","source":"Google Scholar","author":[{"family":"Eppstein","given":"David"}],"issued":{"date-parts":[[2002]]}},
  {"id":"moonenLightweightImpactAnalysis2002","type":"paper-conference","title":"Lightweight Impact Analysis using Island Grammars.","container-title":"IWPC","publisher":"Citeseer","page":"219–228","source":"Google Scholar","author":[{"family":"Moonen","given":"Leon"}],"issued":{"date-parts":[[2002]]}},
  {"id":"haoxiangLanguagesMachinesIntroduction1988","type":"book","title":"Languages and Machines An Introduction to the Theory of Computer Science","publisher":"Addison-Wesley Longman Publishing Co. Inc.","edition":"3rd","abstract":"Preface The objective of the third edition of Languages and Machines: An Introduction to the Theory of Computer Science remains the same as that of the first two editions, to provide a mathematically sound presentation of the theory of computer","ISBN":"0-201-15768-3","language":"en","author":[{"family":"Haoxiang","given":"Ma"}],"issued":{"date-parts":[[1988]]},"publisher-place":"Boston, MA, USA"},
  {"id":"moonenGeneratingRobustParsers2001","type":"paper-conference","title":"Generating robust parsers using island grammars","container-title":"Proceedings Eighth Working Conference on Reverse Engineering","page":"13-22","source":"IEEE Xplore","event":"Proceedings Eighth Working Conference on Reverse Engineering","abstract":"Source model extraction, the automated extraction of information from system artifacts, is a common phase in reverse engineering tools. One of the major challenges of this phase is creating extractors that can deal with irregularities in the artifacts that are typical for the reverse engineering domain (for example, syntactic errors, incomplete source code, language dialects and embedded languages). The paper proposes a solution in the form of island grammars, a special kind of grammar that combines the detailed specification possibilities of grammars with the liberal behavior of lexical approaches. We show how island grammars can be used to generate robust parsers that combine the accuracy of syntactical analysis with the speed, flexibility and tolerance usually only found in lexical analysis. We conclude with a discussion of the development of MANGROVE, a generator for source model extractors based on island grammars and describe its application to a number of case studies.","DOI":"10.1109/WCRE.2001.957806","author":[{"family":"Moonen","given":"L."}],"issued":{"date-parts":[[2001,10]]}},
  {"id":"ghezziFundamentalsSoftwareEngineering2002","type":"book","title":"Fundamentals of Software Engineering","publisher":"Prentice Hall PTR","edition":"2nd","source":"ACM Digital Library","abstract":"From the Publisher:This book provides selective, in-depth coverage of the fundamentals of software engineering by stressing principles and methods through rigorous formal and informal approaches. In contrast to other books which are based on the lifecycle model of software development, the authors emphasize identifying and applying fundamental principles that are applicable throughout the software lifecycle. This emphasis enables readers to respond to the rapid changes in technology that are common today. Principles and techniques are emphasized rather than specific tools—users learn why particular techniques should or should not be used. Understanding the principles and techniques on which tools are based makes mastering a variety of specific tools easier. The authors discuss principles such as design, specification, verification, production, management and tools. Now coverage includes: more detailed analysis and explanation of object-oriented techniques; the use of Unified Modeling Language (UML); requirements analysis and software architecture; Model checking—a technique that provides automatic support to the human activity of software verification; GQM—used to evaluate software quality and help improve the software process; Z specification language. For software engineers.","ISBN":"978-0-13-305699-0","author":[{"family":"Ghezzi","given":"Carlo"},{"family":"Jazayeri","given":"Mehdi"},{"family":"Mandrioli","given":"Dino"}],"issued":{"date-parts":[[2002]]},"publisher-place":"Upper Saddle River, NJ, USA"},
  {"id":"kuramochiFrequentSubgraphDiscovery2001","type":"paper-conference","title":"Frequent subgraph discovery","container-title":"Data Mining, 2001. ICDM 2001, Proceedings IEEE international conference on","publisher":"IEEE","page":"313–320","source":"Google Scholar","author":[{"family":"Kuramochi","given":"Michihiro"},{"family":"Karypis","given":"George"}],"issued":{"date-parts":[[2001]]}},
  {"id":"huanEfficientMiningFrequent2003","type":"paper-conference","title":"Efficient mining of frequent subgraphs in the presence of isomorphism","container-title":"null","publisher":"IEEE","page":"549","source":"Google Scholar","author":[{"family":"Huan","given":"Jun"},{"family":"Wang","given":"Wei"},{"family":"Prins","given":"Jan"}],"issued":{"date-parts":[[2003]]}},
  {"id":"klusenerDerivingTolerantGrammars2003","type":"paper-conference","title":"Deriving tolerant grammars from a base-line grammar","container-title":"Software Maintenance, 2003. ICSM 2003. Proceedings. International Conference on","publisher":"IEEE","page":"179–188","source":"Google Scholar","author":[{"family":"Klusener","given":"Steven"},{"family":"Lammel","given":"Ralf"}],"issued":{"date-parts":[[2003]]}},
  {"id":"kursBoundedSeas2015","type":"article-journal","title":"Bounded seas","container-title":"Computer languages, systems & structures","page":"114–140","volume":"44","source":"Google Scholar","author":[{"family":"Kurš","given":"Jan"},{"family":"Lungu","given":"Mircea"},{"family":"Iyadurai","given":"Rathesan"},{"family":"Nierstrasz","given":"Oscar"}],"issued":{"date-parts":[[2015]]}},
  {"id":"collardXMLbasedLightweightFact2003","type":"paper-conference","title":"An XML-based lightweight C++ fact extractor","container-title":"Program Comprehension, 2003. 11th IEEE International Workshop on","publisher":"IEEE","page":"134–143","source":"Google Scholar","author":[{"family":"Collard","given":"Michael L."},{"family":"Kagdi","given":"Huzefa H."},{"family":"Maletic","given":"Jonathan I."}],"issued":{"date-parts":[[2003]]}},
  {"id":"carrollIslandParsingInterpreter1983","type":"paper-conference","title":"An island parsing interpreter for the full augmented transition network formalism","container-title":"Proceedings of the first conference on European chapter of the Association for Computational Linguistics","publisher":"Association for Computational Linguistics","page":"101–105","source":"Google Scholar","author":[{"family":"Carroll","given":"John A."}],"issued":{"date-parts":[[1983]]}},
  {"id":"carrollIslandParsingInterpreter1982","type":"report","title":"An island parsing interpreter for Augmented Transition Networks","publisher":"University of Cambridge, Computer Laboratory","source":"www.cl.cam.ac.uk","URL":"https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-33.html","number":"UCAM-CL-TR-33","language":"en","author":[{"family":"Carroll","given":"John A."}],"issued":{"date-parts":[[1982]]},"accessed":{"date-parts":[[2019,2,3]]}},
  {"id":"lischkaVirtualNetworkMapping2009","type":"paper-conference","title":"A virtual network mapping algorithm based on subgraph isomorphism detection","container-title":"Proceedings of the 1st ACM workshop on Virtualized infrastructure systems and architectures","publisher":"ACM","page":"81–88","source":"Google Scholar","author":[{"family":"Lischka","given":"Jens"},{"family":"Karl","given":"Holger"}],"issued":{"date-parts":[[2009]]}},
  {"id":"kochEnumeratingAllConnected2001","type":"article-journal","title":"Enumerating all connected maximal common subgraphs in two graphs","container-title":"Theoretical Computer Science","page":"1–30","volume":"250","issue":"1-2","source":"Google Scholar","author":[{"family":"Koch","given":"Ina"}],"issued":{"date-parts":[[2001]]}},
  {"id":"bruneliereMoDiscoGenericExtensible2010","type":"paper-conference","title":"MoDisco: A Generic and Extensible Framework for Model Driven Reverse Engineering","container-title":"Proceedings of the IEEE/ACM International Conference on Automated Software Engineering","collection-title":"ASE '10","publisher":"ACM","page":"173–174","source":"ACM Digital Library","abstract":"Nowadays, almost all companies, independently of their size and type of activity, are facing the problematic of having to manage, maintain or even replace their legacy systems. Many times, the first problem they need to solve is to really understand what are the functionalities, architecture, data, etc of all these often huge legacy applications. As a consequence, reverse engineering still remains a major challenge for software engineering today. This paper introduces MoDisco, a generic and extensible open source reverse engineering solution. MoDisco intensively uses MDE principles and techniques to improve existing approaches for reverse engineering.","URL":"http://doi.acm.org/10.1145/1858996.1859032","DOI":"10.1145/1858996.1859032","ISBN":"978-1-4503-0116-9","title-short":"MoDisco","author":[{"family":"Bruneliere","given":"Hugo"},{"family":"Cabot","given":"Jordi"},{"family":"Jouault","given":"Frédéric"},{"family":"Madiot","given":"Frédéric"}],"issued":{"date-parts":[[2010]]},"accessed":{"date-parts":[[2019,6,10]]},"publisher-place":"New York, NY, USA","event-place":"Antwerp, Belgium"},
  {"id":"huntEfficientAlgorithmsStructural1980","type":"paper-conference","title":"Efficient Algorithms for Structural Similarity of Grammars","container-title":"Proceedings of the 7th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages","collection-title":"POPL '80","publisher":"ACM","page":"213–219","source":"ACM Digital Library","abstract":"Efficient algorithms are presented for several grammar problems relevant to compiler construction. These problems include(i) testing, for a reduced context-free grammar G and an LL(k), uniquely invertible, or BRC(m,n) grammar H, if G is structurally contained by H, and(ii) testing, for a reduced context-free grammar G and a structurally unambiguous grammar H, if G is Reynolds covered by H or if there is an on to homomorphisem from G to H.Related complexity results are presented for several problems for the regular grammars, program schemes, and monadic program schemes.","URL":"http://doi.acm.org/10.1145/567446.567467","DOI":"10.1145/567446.567467","ISBN":"978-0-89791-011-8","author":[{"family":"Hunt","given":"H. B.","suffix":"III"},{"family":"Rosenkrantz","given":"D. J."}],"issued":{"date-parts":[[1980]]},"accessed":{"date-parts":[[2019,6,10]]},"publisher-place":"New York, NY, USA","event-place":"Las Vegas, Nevada"},
  {"id":"almeidaSolvingCyclefreeContextfree2019","type":"article-journal","title":"On solving cycle-free context-free grammar equivalence problem using numerical analysis","container-title":"Journal of Computer Languages","page":"48-56","volume":"51","source":"ScienceDirect","abstract":"In this paper we consider the problem of cycle-free context-free grammars equivalence. To every context-free grammar there corresponds a system of formal equations. Formally applying the iteration method to this system we obtain the grammar axiom in the form of a formal power series composed of the words generated by the grammar ”multiplied” by the respective ambiguities. We define a transform that attributes a matrix meaning to the system of formal equations and to formal power series: terminal symbols are substituted by matrices and formal sum and product are substituted by the matrix ones. In order to effectively compute the sum of a matrix series we numerically solve the system of matrix equations. We prove distinguishability theorems showing that if two formal power series generated by cycle-free context-free grammars are different, then there exists a matrix substitution such that the sums of the respective matrix series are different. Based on this result, we suggest a procedure that can resolve the problem of equivalence of cycle-free context-free grammars in many practical cases. The results obtained in this paper form a theoretical basis for algorithms oriented to automatic assessment of students’ answers in computer science. We present the respective algorithms. Then we compare our approach with a simple heuristic method based on CYK algorithm and discuss the limitations of our method.","URL":"http://www.sciencedirect.com/science/article/pii/S1045926X18301848","DOI":"10.1016/j.cola.2019.02.005","ISSN":"2590-1184","author":[{"family":"Almeida","given":"José João"},{"family":"Grande","given":"Eliana"},{"family":"Smirnov","given":"Georgi"}],"issued":{"date-parts":[[2019,4,1]]},"accessed":{"date-parts":[[2019,6,10]]},"container-title-short":"Journal of Computer Languages"},
  {"id":"paullStructuralEquivalenceContextfree1968","type":"article-journal","title":"Structural equivalence of context-free grammars","container-title":"Journal of Computer and System Sciences","page":"427-463","volume":"2","issue":"4","source":"ScienceDirect","abstract":"Two context-free grammars are defined as being structurally-equivalent if they generate the same sentences and assign similar parse trees (differing only in the labelling of the nodes) to each. It is argued that this type of equivalence is more significant than weak equivalence, which requires only that the same sentences be generated. While the latter type of equivalence is in general undecidable, it is shown here that there exists a finite algorithm for determining if two arbitrary context-free grammars are structurally equivalent. A related result is a procedure for converting an arbitrary context-free grammar into a structurally equivalent “simple” grammar (S-grammar) where this is possible, or else indicating that no such grammar exists. The question of structural ambiguity is also studied and a procedure is given for determining if an arbitrary context-free grammar can generate the same string in 2 different ways with similar parse trees.","URL":"http://www.sciencedirect.com/science/article/pii/S0022000068800376","DOI":"10.1016/S0022-0000(68)80037-6","ISSN":"0022-0000","author":[{"family":"Paull","given":"Marvin C."},{"family":"Unger","given":"Stephen H."}],"issued":{"date-parts":[[1968,12,1]]},"accessed":{"date-parts":[[2019,6,7]]},"container-title-short":"Journal of Computer and System Sciences"},
  {"id":"hanFrequentPatternMining2007","type":"article-journal","title":"Frequent pattern mining: current status and future directions","container-title":"Data mining and knowledge discovery","page":"55–86","volume":"15","issue":"1","source":"Google Scholar","title-short":"Frequent pattern mining","author":[{"family":"Han","given":"Jiawei"},{"family":"Cheng","given":"Hong"},{"family":"Xin","given":"Dong"},{"family":"Yan","given":"Xifeng"}],"issued":{"date-parts":[[2007]]}},
  {"id":"thomasMarginMaximalFrequent2010","type":"article-journal","title":"Margin: Maximal frequent subgraph mining","container-title":"ACM Transactions on Knowledge Discovery from Data (TKDD)","page":"10","volume":"4","issue":"3","source":"Google Scholar","title-short":"Margin","author":[{"family":"Thomas","given":"Lini T."},{"family":"Valluri","given":"Satyanarayana R."},{"family":"Karlapalem","given":"Kamalakar"}],"issued":{"date-parts":[[2010]]}},
  {"id":"linLargescaleFrequentSubgraph2014","type":"paper-conference","title":"Large-scale frequent subgraph mining in MapReduce","container-title":"2014 IEEE 30th International Conference on Data Engineering","publisher":"IEEE","page":"844–855","source":"Google Scholar","author":[{"family":"Lin","given":"Wenqing"},{"family":"Xiao","given":"Xiaokui"},{"family":"Ghinita","given":"Gabriel"}],"issued":{"date-parts":[[2014]]}},
  {"id":"koyuturkEfficientAlgorithmDetecting2004","type":"article-journal","title":"An efficient algorithm for detecting frequent subgraphs in biological networks","container-title":"Bioinformatics","page":"i200–i207","volume":"20","issue":"suppl_1","source":"Google Scholar","author":[{"family":"Koyutürk","given":"Mehmet"},{"family":"Grama","given":"Ananth"},{"family":"Szpankowski","given":"Wojciech"}],"issued":{"date-parts":[[2004]]}},
  {"id":"chiMiningClosedMaximal2005","type":"article-journal","title":"Mining closed and maximal frequent subtrees from databases of labeled rooted trees","container-title":"IEEE Transactions on Knowledge and Data Engineering","page":"190–202","volume":"17","issue":"2","source":"Google Scholar","author":[{"family":"Chi","given":"Yun"},{"family":"Xia","given":"Yi"},{"family":"Yang","given":"Yirong"},{"family":"Muntz","given":"Richard R."}],"issued":{"date-parts":[[2005]]}},
  {"id":"huanSpinMiningMaximal2004","type":"paper-conference","title":"Spin: mining maximal frequent subgraphs from graph databases","container-title":"Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining","publisher":"ACM","page":"581–586","source":"Google Scholar","title-short":"Spin","author":[{"family":"Huan","given":"Jun"},{"family":"Wang","given":"Wei"},{"family":"Prins","given":"Jan"},{"family":"Yang","given":"Jiong"}],"issued":{"date-parts":[[2004]]}},
  {"id":"jiangSurveyFrequentSubgraph2013","type":"article-journal","title":"A survey of frequent subgraph mining algorithms","container-title":"The Knowledge Engineering Review","page":"75–105","volume":"28","issue":"1","source":"Google Scholar","author":[{"family":"Jiang","given":"Chuntao"},{"family":"Coenen","given":"Frans"},{"family":"Zito","given":"Michele"}],"issued":{"date-parts":[[2013]]}},
  {"id":"offuttMutationTestingImplements2006","type":"paper-conference","title":"Mutation testing implements grammar-based testing","container-title":"Second Workshop on Mutation Analysis (Mutation 2006-ISSRE Workshops 2006)","publisher":"IEEE","page":"12–12","source":"Google Scholar","author":[{"family":"Offutt","given":"Jeff"},{"family":"Ammann","given":"Paul"},{"family":"Liu","given":"Lisa"}],"issued":{"date-parts":[[2006]]}},
  {"id":"vanderstormMultilingualProgrammingEnvironments2015","type":"article-journal","title":"Towards multilingual programming environments","container-title":"Science of Computer Programming","collection-title":"Special Issue on New Ideas and Emerging Results in Understanding Software","page":"143-149","volume":"97","source":"ScienceDirect","abstract":"Software projects consist of different kinds of artifacts: build files, configuration files, markup files, source code in different software languages, and so on. At the same time, however, most integrated development environments (IDEs) are focused on a single (programming) language. Even if a programming environment supports multiple languages (e.g., Eclipse), IDE features such as cross-referencing, refactoring, or debugging, do not often cross language boundaries. What would it mean for programming environment to be truly multilingual? In this short paper we sketch a vision of a system that integrates IDE support across language boundaries. We propose to build this system on a foundation of unified source code models and metaprogramming. Nevertheless, a number of important and hard research questions still need to be addressed.","URL":"http://www.sciencedirect.com/science/article/pii/S0167642313003341","DOI":"10.1016/j.scico.2013.11.041","ISSN":"0167-6423","author":[{"family":"Storm","given":"Tijs","non-dropping-particle":"van der"},{"family":"Vinju","given":"Jurgen J."}],"issued":{"date-parts":[[2015,1,1]]},"accessed":{"date-parts":[[2019,7,20]]},"container-title-short":"Science of Computer Programming"},
  {"id":"floresDetectionCrossLanguageSource2011","type":"chapter","title":"Towards the Detection of Cross-Language Source Code Reuse","container-title":"Natural Language Processing and Information Systems","publisher":"Springer Berlin Heidelberg","page":"250-253","volume":"6716","source":"DOI.org (Crossref)","abstract":"Internet has made available huge amounts of information, also source code. Source code repositories and, in general, programming related websites, facilitate its reuse. In this work, we propose a simple approach to the detection of cross-language source code reuse, a nearly investigated problem. Our preliminary experiments, based on character n-grams comparison, show that considering diﬀerent sections of the code (i.e., comments, code, reserved words, etc.), leads to diﬀerent results. When considering three programming languages: C++, Java, and Python, the best result is obtained when comments are discarded and the entire source code is considered.","URL":"http://link.springer.com/10.1007/978-3-642-22327-3_31","ISBN":"978-3-642-22326-6 978-3-642-22327-3","language":"en","editor":[{"family":"Muñoz","given":"Rafael"},{"family":"Montoyo","given":"Andrés"},{"family":"Métais","given":"Elisabeth"}],"author":[{"family":"Flores","given":"Enrique"},{"family":"Barrón-Cedeño","given":"Alberto"},{"family":"Rosso","given":"Paolo"},{"family":"Moreno","given":"Lidia"}],"issued":{"date-parts":[[2011]]},"accessed":{"date-parts":[[2019,7,22]]},"publisher-place":"Berlin, Heidelberg","DOI":"10.1007/978-3-642-22327-3_31"},
  {"id":"colesDemoPITPractical","type":"article-journal","title":"Demo: PIT a Practical Mutation Testing Tool for Java","page":"7","source":"Zotero","language":"en","author":[{"family":"Coles","given":"Henry"},{"family":"Laurent","given":"Thomas"},{"family":"Ventresque","given":"Anthony"}]},
  {"id":"caraccioloPangeaWorkbenchStatically2014","type":"paper-conference","title":"Pangea: A Workbench for Statically Analyzing Multi-language Software Corpora","container-title":"2014 IEEE 14th International Working Conference on Source Code Analysis and Manipulation","publisher":"IEEE","page":"71-76","source":"DOI.org (Crossref)","event":"2014 IEEE 14th International Working Conference on Source Code Analysis and Manipulation (SCAM)","abstract":"Software corpora facilitate reproducibility of analyses, however, static analysis for an entire corpus still requires considerable effort, often duplicated unnecessarily by multiple users. Moreover, most corpora are designed for single languages increasing the effort for cross-language analysis. To address these aspects we propose Pangea, an infrastructure allowing fast development of static analyses on multi-language corpora. Pangea uses language-independent meta-models stored as object model snapshots that can be directly loaded into memory and queryed without any parsing overhead. To reduce the effort of performing static analyses, Pangea provides out-of-the box support for: creating and reﬁning analyses in a dedicated environment, deploying an analysis on an entire corpus, using a runner that supports parallel execution, and exporting results in various formats. In this tool demonstration we introduce Pangea and provide several usage scenarios that illustrate how it reduces the cost of analysis.","URL":"http://ieeexplore.ieee.org/document/6975639/","DOI":"10.1109/SCAM.2014.39","ISBN":"978-1-4799-6148-1","title-short":"Pangea","language":"en","author":[{"family":"Caracciolo","given":"Andrea"},{"family":"Chis","given":"Andrei"},{"family":"Spasojevic","given":"Boris"},{"family":"Lungu","given":"Mircea"}],"issued":{"date-parts":[[2014,9]]},"accessed":{"date-parts":[[2019,7,22]]},"publisher-place":"Victoria, BC, Canada"},
  {"id":"demeyerFAMIX1theFAMOOS2001","type":"article-journal","title":"FAMIX 2. 1-the FAMOOS information exchange model","source":"ResearchGate","author":[{"family":"Demeyer","given":"Serge"},{"family":"Tichelaar","given":"S"},{"family":"Ducasse","given":"Stéphane"}],"issued":{"date-parts":[[2001,1,1]]}},
  {"id":"janesHowCalculateSoftware2013","type":"chapter","title":"How to Calculate Software Metrics for Multiple Languages Using Open Source Parsers","container-title":"Open Source Software: Quality Verification","publisher":"Springer Berlin Heidelberg","page":"264-270","volume":"404","source":"DOI.org (Crossref)","abstract":"Source code metrics help to evaluate the quality of the code, for example, to detect the most complex parts of the program. When writing a system which calculates metrics, especially when it has to support multiple source code languages, the biggest problem which arises is the creation of parsers for each supported language. In this paper we suggest an unusual Open Source solution, that avoids creating such parsers from scratch. We suggest and explain how to use parsers contained in the Eclipse IDE as parsers that support contemporary language features, are actively maintained, can recover from errors, and provide not just the abstract syntax tree, but the whole type information of the source program. The ﬁndings described in this paper provide to practitioners a way to use Open Source parsers without the need to deal with parser generators, or to write a parser from scratch.","URL":"http://link.springer.com/10.1007/978-3-642-38928-3_20","ISBN":"978-3-642-38927-6 978-3-642-38928-3","language":"en","editor":[{"family":"Petrinja","given":"Etiel"},{"family":"Succi","given":"Giancarlo"},{"family":"El Ioini","given":"Nabil"},{"family":"Sillitti","given":"Alberto"}],"author":[{"family":"Janes","given":"Andrea"},{"family":"Piatov","given":"Danila"},{"family":"Sillitti","given":"Alberto"},{"family":"Succi","given":"Giancarlo"}],"issued":{"date-parts":[[2013]]},"accessed":{"date-parts":[[2019,7,22]]},"publisher-place":"Berlin, Heidelberg","DOI":"10.1007/978-3-642-38928-3_20"}
]
