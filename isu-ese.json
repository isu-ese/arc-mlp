[
  {"id":"gareyComputersIntractabilityGuide1979","type":"book","abstract":"Summary: \"Shows how to recognize NP-complete problems and offers proactical suggestions for dealing with them effectively. The book covers the basic theory of NP-completeness, provides an overview of alternative directions for further research, and contains and extensive list of NP-complete and NP-hard problems, with more than 300 main entries and several times as many results in total. [This book] is suitable as a supplement to courses in algorithm design, computational complexity, operations research, or combinatorial mathematics, and as a text for seminars on approximation algorithms or computational complexity. It provides not only a valuable source of information for students but also an essential reference work for professionals in computer science\"--Back cover.","archive_location":"Main Book Collection (2nd Floor) QA76.6","collection-title":"Series of books in the mathematical sciences","ISBN":"978-0-7167-1045-5","publisher":"W.H. Freeman","source":"EBSCOhost","title":"Computers and intractability: A  guide to the theory of NP-completeness","title-short":"Computers and intractability","author":[{"family":"Garey","given":"Michael R."},{"family":"Johnson","given":"David S."}],"issued":{"date-parts":[[1979]]}},
  {"id":"mushtaqMultilingualSourceCode2017","type":"article-journal","abstract":"Contemporary software applications are developed using cross-language artifacts, which are interdependent with each other. The source code analysis of these applications requires the extraction and examination of artifacts, which are build using multiple programming languages along with their dependencies. A large number of studies presented on multilingual source code analysis and its applications in the last one and half decade. The objective of this systematic literature review (SLR) is to summarize state of the art and prominent areas for future research. This SLR is based on different techniques, tools, and methodologies to analyze multilingual source code applications. We finalized 56 multi-discipline published papers relevant to multilingual source code analysis and its applications out of 3820 papers, filtered through multi-stage search criterion. Based on our findings, we highlight research gaps and challenges in the field of multilingual applications. The research findings are presented in the form of research problems, research contributions, challenges, and future prospects. We identified 46 research issues and requirements for analyzing multilingual applications and grouped them in 13 different software engineering domains. We examined the research contributions and mapped them with individual research problems. We presented the research contributions in the form of tools techniques and approaches that are presented in the form of research models, platforms, frameworks, prototype models, and case studies. Every research has its limitations or prospects for future research. We highlighted the limitations and future perspectives and grouped them in various software engineering domains. Most of the research trends and potential research areas are identified in static source code analysis, program comprehension, refactoring, reverse engineering, detection, and traceability of cross-language links, code coverage, security analysis, cross-language parsing, and abstraction of source code models.","container-title":"IEEE Access","DOI":"10.1109/ACCESS.2017.2710421","ISSN":"2169-3536","page":"11307-11336","source":"IEEE Xplore","title":"Multilingual Source Code Analysis: A Systematic Literature Review","title-short":"Multilingual Source Code Analysis","volume":"5","author":[{"family":"Mushtaq","given":"Z."},{"family":"Rasool","given":"G."},{"family":"Shehzad","given":"B."}],"issued":{"date-parts":[[2017]]}},
  {"id":"durandEfficientAlgorithmSimilarity1999","type":"article-journal","container-title":"Internet Journal of Chemistry","issue":"17","page":"1–16","source":"Google Scholar","title":"An efficient algorithm for similarity analysis of molecules","volume":"2","author":[{"family":"Durand","given":"Paul J."},{"family":"Pasari","given":"Rohit"},{"family":"Baker","given":"Johnnie W."},{"family":"Tsai","given":"Chun-che"}],"issued":{"date-parts":[[1999]]}},
  {"id":"wellingPerformanceAnalysisMaximal2011","type":"paper-conference","abstract":"Graphs can be used as a tool to determine similarity between structured objects. The maximal common subgraph of two graphs G and H is the largest graph in terms of edges that is isomorphic to a subgraph of G and H. Finding the maximal common subgraph is an NP-complete problem. It is useful in many areas like (bio)chemistry, file versioning and artificial intelligence. There are many papers that evaluate algorithms for finding maximal common induced subgraphs, but little research has been done on the maximal common subgraph that is not an induced subgraph. We have implemented and benchmarked two maximal common (not induced) subgraph algorithms: a backtrack search algorithm (McGregor), and an algorithm that transforms the maximal common subgraph problem to the largest clique problem (Koch). We created generators for randomly connected and mesh structured graphs, these generators have been used to create a database of graph pairs to benchmark the two algorithms. The results of our benchmark have shown that in most cases Koch is more efficient, because after creating the edge product graph needed for the clique detection. The actual clique detection is a relatively simple search.","source":"Semantic Scholar","title":"A Performance Analysis on Maximal Common Subgraph Algorithms","author":[{"family":"Welling","given":"Ruud"}],"issued":{"date-parts":[[2011]]}},
  {"id":"conteChallengingComplexityMaximum2007","type":"article-journal","abstract":"Graphs are an extremely general and powerful data structure. In pattern recognition and computer vision, graphs are used to represent patterns to be recognized or classified. Detection of maximum common subgraph (MCS) is useful for matching, comparing and evaluate the similarity of patterns. MCS is a well known NP-complete problem for which optimal and suboptimal algorithms are known from the literature. Nevertheless, until now no effort has been done for characterizing their performance. The lack of a large database of graphs makes the task of comparing the performance of different graph matching algorithms difficult, and often the selection of an algorithm is made on the basis of a few experimental results available. In this paper, three optimal and well-known algorithms for maximum common subgraph detection are described. Moreover a large database containing various categories of pairs of graphs (e.g. random graphs, meshes, bounded valence graphs), is presented, and the performance of the three algorithms is evaluated on this database. Article Type Communicated by Submitted Revised Regular Paper U. Brandes September 2005 January 2007 D. Conte et al., Maximum Common Subgraph, JGAA, 11(1) 99–143 (2007) 100","container-title":"J. Graph Algorithms Appl.","DOI":"10.7155/jgaa.00139","page":"99-143","source":"Semantic Scholar","title":"Challenging Complexity of Maximum Common Subgraph Detection Algorithms: A Performance Analysis of Three Algorithms on a Wide Database of Graphs","title-short":"Challenging Complexity of Maximum Common Subgraph Detection Algorithms","volume":"11","author":[{"family":"Conte","given":"Donatello"},{"family":"Foggia","given":"Pasquale"},{"family":"Vento","given":"Mario"}],"issued":{"date-parts":[[2007]]}},
  {"id":"conteComparisonThreeMaximum2003","type":"paper-conference","abstract":"A graph g is called a maximum common subgraph of two graphs, g1 and g2, if there exists no other common subgraph of g1 and g2 that has more nodes than g. For the maximum common subgraph problem, exact and inexact algorithms are known from the literature. Nevertheless, until now no effort has been done for characterizing their performance, mainly for the lack of a large database of graphs. In this paper, three exact and well-known algorithms for maximum common subgraph detection are described. Moreover, a large database containing various categories of pairs of graphs (e.g. randomly connected graphs, meshes, bounded valence graphs...), having a maximum common subgraph of at least two nodes, is presented, and the performance of the three algorithms is evaluated on this database.","collection-title":"GbRPR'03","container-title":"Proceedings of the 4th IAPR International Conference on Graph Based Representations in Pattern Recognition","ISBN":"978-3-540-40452-1","page":"130–141","publisher":"Springer-Verlag","source":"ACM Digital Library","title":"A Comparison of Three Maximum Common Subgraph Algorithms on a Large Database of Labeled Graphs","URL":"http://dl.acm.org/citation.cfm?id=1757868.1757884","author":[{"family":"Conte","given":"D."},{"family":"Guidobaldi","given":"C."},{"family":"Sansone","given":"C."}],"accessed":{"date-parts":[[2019,5,10]]},"issued":{"date-parts":[[2003]]},"publisher-place":"Berlin, Heidelberg","event-place":"York, UK"},
  {"id":"raymondMaximumCommonSubgraph","type":"article-journal","abstract":"The maximum common subgraph (MCS) problem has become increasingly important in those aspects of chemoinformatics that involve the matching of 2D or 3D chemical structures. This paper provides a classiﬁcation and a review of the many MCS algorithms, both exact and approximate, that have been described in the literature, and makes recommendations regarding their applicability to typical chemoinformatics tasks.","language":"en","page":"13","source":"Zotero","title":"Maximum common subgraph isomorphism algorithms for the matching of chemical structures","author":[{"family":"Raymond","given":"John W"},{"family":"Willett","given":"Peter"}]},
  {"id":"tomitaWorstcaseTimeComplexity2006","type":"article-journal","abstract":"We present a depth-first search algorithm for generating all maximal cliques of an undirected graph, in which pruning methods are employed as in the Bron–Kerbosch algorithm. All the maximal cliques generated are output in a tree-like form. Subsequently, we prove that its worst-case time complexity is O(3n/3) for an n-vertex graph. This is optimal as a function of n, since there exist up to 3n/3 maximal cliques in an n-vertex graph. The algorithm is also demonstrated to run very fast in practice by computational experiments.","collection-title":"Computing and Combinatorics","container-title":"Theoretical Computer Science","DOI":"10.1016/j.tcs.2006.06.015","ISSN":"0304-3975","issue":"1","page":"28-42","source":"ScienceDirect","title":"The worst-case time complexity for generating all maximal cliques and computational experiments","URL":"http://www.sciencedirect.com/science/article/pii/S0304397506003586","volume":"363","author":[{"family":"Tomita","given":"Etsuji"},{"family":"Tanaka","given":"Akira"},{"family":"Takahashi","given":"Haruhisa"}],"accessed":{"date-parts":[[2019,5,9]]},"issued":{"date-parts":[[2006,10,25]]},"container-title-short":"Theoretical Computer Science"},
  {"id":"bettenburgWhatMakesGood2008","type":"paper-conference","container-title":"Proceedings of the 16th ACM SIGSOFT International Symposium on Foundations of software engineering","page":"308–318","publisher":"ACM","source":"Google Scholar","title":"What makes a good bug report?","author":[{"family":"Bettenburg","given":"Nicolas"},{"family":"Just","given":"Sascha"},{"family":"Schröter","given":"Adrian"},{"family":"Weiss","given":"Cathrin"},{"family":"Premraj","given":"Rahul"},{"family":"Zimmermann","given":"Thomas"}],"issued":{"date-parts":[[2008]]}},
  {"id":"bastaniSynthesizingProgramInput2017","type":"paper-conference","abstract":"We present an algorithm for synthesizing a context-free grammar encoding the language of valid program inputs from a set of input examples and blackbox access to the program. Our algorithm addresses shortcomings of existing grammar inference algorithms, which both severely overgeneralize and are prohibitively slow. Our implementation, GLADE, leverages the grammar synthesized by our algorithm to fuzz test programs with structured inputs. We show that GLADE substantially increases the incremental coverage on valid inputs compared to two baseline fuzzers.","container-title":"Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation  - PLDI 2017","DOI":"10.1145/3062341.3062349","event":"the 38th ACM SIGPLAN Conference","ISBN":"978-1-4503-4988-8","language":"en","page":"95-110","publisher":"ACM Press","source":"DOI.org (Crossref)","title":"Synthesizing program input grammars","URL":"http://dl.acm.org/citation.cfm?doid=3062341.3062349","author":[{"family":"Bastani","given":"Osbert"},{"family":"Sharma","given":"Rahul"},{"family":"Aiken","given":"Alex"},{"family":"Liang","given":"Percy"}],"accessed":{"date-parts":[[2019,4,18]]},"issued":{"date-parts":[[2017]]},"publisher-place":"Barcelona, Spain"},
  {"id":"klintEngineeringDisciplineGrammarware2005","type":"article-journal","container-title":"ACM Transactions on Software Engineering and Methodology","DOI":"10.1145/1072997.1073000","ISSN":"1049331X","issue":"3","language":"en","page":"331-380","source":"DOI.org (Crossref)","title":"Toward an engineering discipline for grammarware","URL":"http://portal.acm.org/citation.cfm?doid=1072997.1073000","volume":"14","author":[{"family":"Klint","given":"Paul"},{"family":"Lämmel","given":"Ralf"},{"family":"Verhoef","given":"Chris"}],"accessed":{"date-parts":[[2019,4,18]]},"issued":{"date-parts":[[2005,7,1]]}},
  {"id":"goloveshkinTolerantParsingSpecial2018","type":"article-journal","abstract":"Tolerant parsing is a form of syntax analysis aimed at capturing the structure of certain points of interest presented in a source code. While these points should be welldescribed in the corresponding language grammar, other parts of the program are allowed to be not presented in the grammar or to be described coarse-grained, thereby parser remains tolerant to the possible inconsistencies in the irrelevant area. Island grammars are one of the basic tolerant parsing techniques. “Island” is used as the relevant code alias, while the irrelevant code is called “water”. In the paper, a modified LL(1) parsing algorithm with built-in “Any” symbol processing is described. The “Any” symbol matches implicitly defined token sequences. The use of the algorithm for island grammars allows one to reduce irrelevant code description as well as to simplify patterns for relevant code matching. Our “Any” implementation is more accurate and less restrictive in comparison with the closest analogues implemented in Coco/R and LightParse parser generators. It also has potentially lower overhead than the “bounded seas” concept implemented in PetitParser. As shown in the experimental section, the tolerant parser generated by the C# island grammar is proven to be applicable for large-scale software projects analysis.","container-title":"Proceedings of the Institute for System Programming of the RAS","DOI":"10.15514/ISPRAS-2018-30(4)-1","ISSN":"20798156, 22206426","issue":"4","language":"en","page":"7-28","source":"DOI.org (Crossref)","title":"Tolerant parsing with a special kind of «Any» symbol: the algorithm and practical application","title-short":"Tolerant parsing with a special kind of «Any» symbol","URL":"http://www.ispras.ru/en/proceedings/isp_30_2018_4/isp_30_2018_4_7/","volume":"30","author":[{"family":"Goloveshkin","given":"A.V."},{"family":"Mikhalkovich","given":"S.S."}],"accessed":{"date-parts":[[2019,4,19]]},"issued":{"date-parts":[[2018]]}},
  {"id":"shangTamingVerificationHardness2008","type":"article-journal","container-title":"Proceedings of the VLDB Endowment","issue":"1","page":"364–375","source":"Google Scholar","title":"Taming verification hardness: an efficient algorithm for testing subgraph isomorphism","title-short":"Taming verification hardness","volume":"1","author":[{"family":"Shang","given":"Haichuan"},{"family":"Zhang","given":"Ying"},{"family":"Lin","given":"Xuemin"},{"family":"Yu","given":"Jeffrey Xu"}],"issued":{"date-parts":[[2008]]}},
  {"id":"synytskyyRobustMultilingualParsing2003","type":"paper-conference","container-title":"Proceedings of the 2003 conference of the Centre for Advanced Studies on Collaborative research","page":"266–278","publisher":"IBM Press","source":"Google Scholar","title":"Robust multilingual parsing using island grammars","author":[{"family":"Synytskyy","given":"Nikita"},{"family":"Cordy","given":"James R."},{"family":"Dean","given":"Thomas R."}],"issued":{"date-parts":[[2003]]}},
  {"id":"grindleyIdentificationTertiaryStructure1993","type":"article-journal","container-title":"Journal of molecular biology","issue":"3","page":"707–721","source":"Google Scholar","title":"Identification of tertiary structure resemblance in proteins using a maximal common subgraph isomorphism algorithm","volume":"229","author":[{"family":"Grindley","given":"Helen M."},{"family":"Artymiuk","given":"Peter J."},{"family":"Rice","given":"David W."},{"family":"Willett","given":"Peter"}],"issued":{"date-parts":[[1993]]}},
  {"id":"bacchelliExtractingStructuredData2011","type":"paper-conference","container-title":"Automated Software Engineering (ASE), 2011 26th IEEE/ACM International Conference on","page":"476–479","publisher":"IEEE","source":"Google Scholar","title":"Extracting structured data from natural language documents with island parsing","author":[{"family":"Bacchelli","given":"Alberto"},{"family":"Cleve","given":"Anthony"},{"family":"Lanza","given":"Michele"},{"family":"Mocci","given":"Andrea"}],"issued":{"date-parts":[[2011]]}},
  {"id":"streinCrosslanguageProgramAnalysis2006","type":"paper-conference","container-title":"2006 Sixth IEEE International Workshop on Source Code Analysis and Manipulation","page":"207–216","publisher":"IEEE","source":"Google Scholar","title":"Cross-language program analysis and refactoring","author":[{"family":"Strein","given":"Dennis"},{"family":"Kratz","given":"Hans"},{"family":"Lowe","given":"Welf"}],"issued":{"date-parts":[[2006]]}},
  {"id":"reinhardwilhelmCompilerDesign1995","type":"book","ISBN":"0-201-42290-5","number-of-pages":"606","publisher":"Addison-Wesley","title":"Compiler Design","author":[{"family":"Reinhard Wilhelm","given":"Dieter Maurer"}],"issued":{"date-parts":[[1995,1,1]]},"publisher-place":"Boston, United States"},
  {"id":"deursenBuildingDocumentationGenerators1999","type":"paper-conference","abstract":"In order to maintain the consistency between sources and documentation, while at the same time providing documentation at the design level, it is necessary to generate documentation from sources in such a way that it can be integrated with hand-written documentation. In order to simplify the construction of documentation generators, we introduce island grammars, which only define those syntactic structures needed for (re)documentation purposes. We explain how they can be used to obtain various forms of documentation, such as data dependency diagrams for mainframe batch jobs. Moreover, we discuss how the derived information can be made available via a hypertext structure. We conclude with an industrial case study in which a 600,000 LOC COBOL legacy system is redocumented using the techniques presented in the paper.","container-title":"Proceedings IEEE International Conference on Software Maintenance - 1999 (ICSM'99). 'Software Maintenance for Business Change' (Cat. No.99CB36360)","DOI":"10.1109/ICSM.1999.792497","event":"Proceedings IEEE International Conference on Software Maintenance - 1999 (ICSM'99). 'Software Maintenance for Business Change' (Cat. No.99CB36360)","page":"40-49","source":"IEEE Xplore","title":"Building documentation generators","author":[{"family":"Deursen","given":"A. Van"},{"family":"Kuipers","given":"T."}],"issued":{"date-parts":[[1999,8]]}},
  {"id":"ullmannAlgorithmSubgraphIsomorphism1976","type":"article-journal","container-title":"Journal of the ACM (JACM)","issue":"1","page":"31–42","source":"Google Scholar","title":"An algorithm for subgraph isomorphism","volume":"23","author":[{"family":"Ullmann","given":"Julian R."}],"issued":{"date-parts":[[1976]]}},
  {"id":"messmerNewAlgorithmErrortolerant1998","type":"article-journal","container-title":"IEEE Transactions on Pattern Analysis and Machine Intelligence","issue":"5","page":"493–504","source":"Google Scholar","title":"A new algorithm for error-tolerant subgraph isomorphism detection","volume":"20","author":[{"family":"Messmer","given":"Bruno T."},{"family":"Bunke","given":"Horst"}],"issued":{"date-parts":[[1998]]}},
  {"id":"bunkeComparisonAlgorithmsMaximum2002","type":"paper-conference","container-title":"Joint IAPR International Workshops on Statistical Techniques in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition (SSPR)","page":"123–132","publisher":"Springer","source":"Google Scholar","title":"A comparison of algorithms for maximum common subgraph on randomly connected graphs","author":[{"family":"Bunke","given":"Horst"},{"family":"Foggia","given":"Pasquale"},{"family":"Guidobaldi","given":"Corrado"},{"family":"Sansone","given":"Carlo"},{"family":"Vento","given":"Mario"}],"issued":{"date-parts":[[2002]]}},
  {"id":"cordellaSubGraphIsomorphism2004","type":"article-journal","container-title":"IEEE transactions on pattern analysis and machine intelligence","issue":"10","page":"1367–1372","source":"Google Scholar","title":"A (sub) graph isomorphism algorithm for matching large graphs","volume":"26","author":[{"family":"Cordella","given":"Luigi P."},{"family":"Foggia","given":"Pasquale"},{"family":"Sansone","given":"Carlo"},{"family":"Vento","given":"Mario"}],"issued":{"date-parts":[[2004]]}},
  {"id":"eppsteinSubgraphIsomorphismPlanar2002","type":"chapter","container-title":"Graph Algorithms And Applications I","page":"283–309","publisher":"World Scientific","source":"Google Scholar","title":"Subgraph isomorphism in planar graphs and related problems","author":[{"family":"Eppstein","given":"David"}],"issued":{"date-parts":[[2002]]}},
  {"id":"moonenLightweightImpactAnalysis2002","type":"paper-conference","container-title":"IWPC","page":"219–228","publisher":"Citeseer","source":"Google Scholar","title":"Lightweight Impact Analysis using Island Grammars.","author":[{"family":"Moonen","given":"Leon"}],"issued":{"date-parts":[[2002]]}},
  {"id":"haoxiangLanguagesMachinesIntroduction1988","type":"book","abstract":"Preface The objective of the third edition of Languages and Machines: An Introduction to the Theory of Computer Science remains the same as that of the first two editions, to provide a mathematically sound presentation of the theory of computer","edition":"3rd","ISBN":"0-201-15768-3","language":"en","publisher":"Addison-Wesley Longman Publishing Co. Inc.","title":"Languages and Machines: An Introduction to the Theory of Computer Science","author":[{"family":"Haoxiang","given":"Ma"}],"issued":{"date-parts":[[1988]]},"publisher-place":"Boston, MA, USA"},
  {"id":"moonenGeneratingRobustParsers2001","type":"paper-conference","abstract":"Source model extraction, the automated extraction of information from system artifacts, is a common phase in reverse engineering tools. One of the major challenges of this phase is creating extractors that can deal with irregularities in the artifacts that are typical for the reverse engineering domain (for example, syntactic errors, incomplete source code, language dialects and embedded languages). The paper proposes a solution in the form of island grammars, a special kind of grammar that combines the detailed specification possibilities of grammars with the liberal behavior of lexical approaches. We show how island grammars can be used to generate robust parsers that combine the accuracy of syntactical analysis with the speed, flexibility and tolerance usually only found in lexical analysis. We conclude with a discussion of the development of MANGROVE, a generator for source model extractors based on island grammars and describe its application to a number of case studies.","container-title":"Proceedings Eighth Working Conference on Reverse Engineering","DOI":"10.1109/WCRE.2001.957806","event":"Proceedings Eighth Working Conference on Reverse Engineering","page":"13-22","source":"IEEE Xplore","title":"Generating robust parsers using island grammars","author":[{"family":"Moonen","given":"L."}],"issued":{"date-parts":[[2001,10]]}},
  {"id":"ghezziFundamentalsSoftwareEngineering2002","type":"book","abstract":"From the Publisher:This book provides selective, in-depth coverage of the fundamentals of software engineering by stressing principles and methods through rigorous formal and informal approaches. In contrast to other books which are based on the lifecycle model of software development, the authors emphasize identifying and applying fundamental principles that are applicable throughout the software lifecycle. This emphasis enables readers to respond to the rapid changes in technology that are common today. Principles and techniques are emphasized rather than specific tools—users learn why particular techniques should or should not be used. Understanding the principles and techniques on which tools are based makes mastering a variety of specific tools easier. The authors discuss principles such as design, specification, verification, production, management and tools. Now coverage includes: more detailed analysis and explanation of object-oriented techniques; the use of Unified Modeling Language (UML); requirements analysis and software architecture; Model checking—a technique that provides automatic support to the human activity of software verification; GQM—used to evaluate software quality and help improve the software process; Z specification language. For software engineers.","edition":"2nd","ISBN":"978-0-13-305699-0","publisher":"Prentice Hall PTR","source":"ACM Digital Library","title":"Fundamentals of Software Engineering","author":[{"family":"Ghezzi","given":"Carlo"},{"family":"Jazayeri","given":"Mehdi"},{"family":"Mandrioli","given":"Dino"}],"issued":{"date-parts":[[2002]]},"publisher-place":"Upper Saddle River, NJ, USA"},
  {"id":"kuramochiFrequentSubgraphDiscovery2001","type":"paper-conference","container-title":"Data Mining, 2001. ICDM 2001, Proceedings IEEE international conference on","page":"313–320","publisher":"IEEE","source":"Google Scholar","title":"Frequent subgraph discovery","author":[{"family":"Kuramochi","given":"Michihiro"},{"family":"Karypis","given":"George"}],"issued":{"date-parts":[[2001]]}},
  {"id":"huanEfficientMiningFrequent2003","type":"paper-conference","container-title":"null","page":"549","publisher":"IEEE","source":"Google Scholar","title":"Efficient mining of frequent subgraphs in the presence of isomorphism","author":[{"family":"Huan","given":"Jun"},{"family":"Wang","given":"Wei"},{"family":"Prins","given":"Jan"}],"issued":{"date-parts":[[2003]]}},
  {"id":"klusenerDerivingTolerantGrammars2003","type":"paper-conference","container-title":"International Conference on Software Maintenance","page":"179–188","publisher":"IEEE","source":"Google Scholar","title":"Deriving tolerant grammars from a base-line grammar","author":[{"family":"Klusener","given":"Steven"},{"family":"Lammel","given":"Ralf"}],"issued":{"date-parts":[[2003]]}},
  {"id":"kursBoundedSeas2015","type":"article-journal","container-title":"Computer languages, systems & structures","page":"114–140","source":"Google Scholar","title":"Bounded seas","volume":"44","author":[{"family":"Kurš","given":"Jan"},{"family":"Lungu","given":"Mircea"},{"family":"Iyadurai","given":"Rathesan"},{"family":"Nierstrasz","given":"Oscar"}],"issued":{"date-parts":[[2015]]}},
  {"id":"collardXMLbasedLightweightFact2003","type":"paper-conference","container-title":"Program Comprehension, 2003. 11th IEEE International Workshop on","page":"134–143","publisher":"IEEE","source":"Google Scholar","title":"An XML-based lightweight C++ fact extractor","author":[{"family":"Collard","given":"Michael L."},{"family":"Kagdi","given":"Huzefa H."},{"family":"Maletic","given":"Jonathan I."}],"issued":{"date-parts":[[2003]]}},
  {"id":"carrollIslandParsingInterpreter1983","type":"paper-conference","container-title":"Proceedings of the first conference on European chapter of the Association for Computational Linguistics","page":"101–105","publisher":"Association for Computational Linguistics","source":"Google Scholar","title":"An island parsing interpreter for the full augmented transition network formalism","author":[{"family":"Carroll","given":"John A."}],"issued":{"date-parts":[[1983]]}},
  {"id":"carrollIslandParsingInterpreter1982","type":"report","language":"en","number":"UCAM-CL-TR-33","publisher":"University of Cambridge, Computer Laboratory","source":"www.cl.cam.ac.uk","title":"An island parsing interpreter for Augmented Transition Networks","URL":"https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-33.html","author":[{"family":"Carroll","given":"John A."}],"accessed":{"date-parts":[[2019,2,3]]},"issued":{"date-parts":[[1982]]}},
  {"id":"lischkaVirtualNetworkMapping2009","type":"paper-conference","container-title":"Proceedings of the 1st ACM workshop on Virtualized infrastructure systems and architectures","page":"81–88","publisher":"ACM","source":"Google Scholar","title":"A virtual network mapping algorithm based on subgraph isomorphism detection","author":[{"family":"Lischka","given":"Jens"},{"family":"Karl","given":"Holger"}],"issued":{"date-parts":[[2009]]}},
  {"id":"kochEnumeratingAllConnected2001","type":"article-journal","container-title":"Theoretical Computer Science","issue":"1-2","page":"1–30","source":"Google Scholar","title":"Enumerating all connected maximal common subgraphs in two graphs","volume":"250","author":[{"family":"Koch","given":"Ina"}],"issued":{"date-parts":[[2001]]}},
  {"id":"bruneliereMoDiscoGenericExtensible2010","type":"paper-conference","abstract":"Nowadays, almost all companies, independently of their size and type of activity, are facing the problematic of having to manage, maintain or even replace their legacy systems. Many times, the first problem they need to solve is to really understand what are the functionalities, architecture, data, etc of all these often huge legacy applications. As a consequence, reverse engineering still remains a major challenge for software engineering today. This paper introduces MoDisco, a generic and extensible open source reverse engineering solution. MoDisco intensively uses MDE principles and techniques to improve existing approaches for reverse engineering.","collection-title":"ASE '10","container-title":"Proceedings of the IEEE/ACM International Conference on Automated Software Engineering","DOI":"10.1145/1858996.1859032","ISBN":"978-1-4503-0116-9","page":"173–174","publisher":"ACM","source":"ACM Digital Library","title":"MoDisco: A Generic and Extensible Framework for Model Driven Reverse Engineering","title-short":"MoDisco","URL":"http://doi.acm.org/10.1145/1858996.1859032","author":[{"family":"Bruneliere","given":"Hugo"},{"family":"Cabot","given":"Jordi"},{"family":"Jouault","given":"Frédéric"},{"family":"Madiot","given":"Frédéric"}],"accessed":{"date-parts":[[2019,6,10]]},"issued":{"date-parts":[[2010]]},"publisher-place":"New York, NY, USA","event-place":"Antwerp, Belgium"},
  {"id":"huntEfficientAlgorithmsStructural1980","type":"paper-conference","abstract":"Efficient algorithms are presented for several grammar problems relevant to compiler construction. These problems include(i) testing, for a reduced context-free grammar G and an LL(k), uniquely invertible, or BRC(m,n) grammar H, if G is structurally contained by H, and(ii) testing, for a reduced context-free grammar G and a structurally unambiguous grammar H, if G is Reynolds covered by H or if there is an on to homomorphisem from G to H.Related complexity results are presented for several problems for the regular grammars, program schemes, and monadic program schemes.","collection-title":"POPL '80","container-title":"Proceedings of the 7th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages","DOI":"10.1145/567446.567467","ISBN":"978-0-89791-011-8","page":"213–219","publisher":"ACM","source":"ACM Digital Library","title":"Efficient Algorithms for Structural Similarity of Grammars","URL":"http://doi.acm.org/10.1145/567446.567467","author":[{"family":"Hunt","given":"H. B.","suffix":"III"},{"family":"Rosenkrantz","given":"D. J."}],"accessed":{"date-parts":[[2019,6,10]]},"issued":{"date-parts":[[1980]]},"publisher-place":"New York, NY, USA","event-place":"Las Vegas, Nevada"},
  {"id":"almeidaSolvingCyclefreeContextfree2019","type":"article-journal","abstract":"In this paper we consider the problem of cycle-free context-free grammars equivalence. To every context-free grammar there corresponds a system of formal equations. Formally applying the iteration method to this system we obtain the grammar axiom in the form of a formal power series composed of the words generated by the grammar ”multiplied” by the respective ambiguities. We define a transform that attributes a matrix meaning to the system of formal equations and to formal power series: terminal symbols are substituted by matrices and formal sum and product are substituted by the matrix ones. In order to effectively compute the sum of a matrix series we numerically solve the system of matrix equations. We prove distinguishability theorems showing that if two formal power series generated by cycle-free context-free grammars are different, then there exists a matrix substitution such that the sums of the respective matrix series are different. Based on this result, we suggest a procedure that can resolve the problem of equivalence of cycle-free context-free grammars in many practical cases. The results obtained in this paper form a theoretical basis for algorithms oriented to automatic assessment of students’ answers in computer science. We present the respective algorithms. Then we compare our approach with a simple heuristic method based on CYK algorithm and discuss the limitations of our method.","container-title":"Journal of Computer Languages","DOI":"10.1016/j.cola.2019.02.005","ISSN":"2590-1184","page":"48-56","source":"ScienceDirect","title":"On solving cycle-free context-free grammar equivalence problem using numerical analysis","URL":"http://www.sciencedirect.com/science/article/pii/S1045926X18301848","volume":"51","author":[{"family":"Almeida","given":"José João"},{"family":"Grande","given":"Eliana"},{"family":"Smirnov","given":"Georgi"}],"accessed":{"date-parts":[[2019,6,10]]},"issued":{"date-parts":[[2019,4,1]]},"container-title-short":"Journal of Computer Languages"},
  {"id":"paullStructuralEquivalenceContextfree1968","type":"article-journal","abstract":"Two context-free grammars are defined as being structurally-equivalent if they generate the same sentences and assign similar parse trees (differing only in the labelling of the nodes) to each. It is argued that this type of equivalence is more significant than weak equivalence, which requires only that the same sentences be generated. While the latter type of equivalence is in general undecidable, it is shown here that there exists a finite algorithm for determining if two arbitrary context-free grammars are structurally equivalent. A related result is a procedure for converting an arbitrary context-free grammar into a structurally equivalent “simple” grammar (S-grammar) where this is possible, or else indicating that no such grammar exists. The question of structural ambiguity is also studied and a procedure is given for determining if an arbitrary context-free grammar can generate the same string in 2 different ways with similar parse trees.","container-title":"Journal of Computer and System Sciences","DOI":"10.1016/S0022-0000(68)80037-6","ISSN":"0022-0000","issue":"4","page":"427-463","source":"ScienceDirect","title":"Structural equivalence of context-free grammars","URL":"http://www.sciencedirect.com/science/article/pii/S0022000068800376","volume":"2","author":[{"family":"Paull","given":"Marvin C."},{"family":"Unger","given":"Stephen H."}],"accessed":{"date-parts":[[2019,6,7]]},"issued":{"date-parts":[[1968,12,1]]},"container-title-short":"Journal of Computer and System Sciences"},
  {"id":"hanFrequentPatternMining2007","type":"article-journal","container-title":"Data mining and knowledge discovery","issue":"1","page":"55–86","source":"Google Scholar","title":"Frequent pattern mining: current status and future directions","title-short":"Frequent pattern mining","volume":"15","author":[{"family":"Han","given":"Jiawei"},{"family":"Cheng","given":"Hong"},{"family":"Xin","given":"Dong"},{"family":"Yan","given":"Xifeng"}],"issued":{"date-parts":[[2007]]}},
  {"id":"thomasMarginMaximalFrequent2010","type":"article-journal","container-title":"ACM Transactions on Knowledge Discovery from Data (TKDD)","issue":"3","page":"10","source":"Google Scholar","title":"Margin: Maximal frequent subgraph mining","title-short":"Margin","volume":"4","author":[{"family":"Thomas","given":"Lini T."},{"family":"Valluri","given":"Satyanarayana R."},{"family":"Karlapalem","given":"Kamalakar"}],"issued":{"date-parts":[[2010]]}},
  {"id":"linLargescaleFrequentSubgraph2014","type":"paper-conference","container-title":"2014 IEEE 30th International Conference on Data Engineering","page":"844–855","publisher":"IEEE","source":"Google Scholar","title":"Large-scale frequent subgraph mining in MapReduce","author":[{"family":"Lin","given":"Wenqing"},{"family":"Xiao","given":"Xiaokui"},{"family":"Ghinita","given":"Gabriel"}],"issued":{"date-parts":[[2014]]}},
  {"id":"koyuturkEfficientAlgorithmDetecting2004","type":"article-journal","container-title":"Bioinformatics","issue":"suppl_1","page":"i200–i207","source":"Google Scholar","title":"An efficient algorithm for detecting frequent subgraphs in biological networks","volume":"20","author":[{"family":"Koyutürk","given":"Mehmet"},{"family":"Grama","given":"Ananth"},{"family":"Szpankowski","given":"Wojciech"}],"issued":{"date-parts":[[2004]]}},
  {"id":"chiMiningClosedMaximal2005","type":"article-journal","container-title":"IEEE Transactions on Knowledge and Data Engineering","issue":"2","page":"190–202","source":"Google Scholar","title":"Mining closed and maximal frequent subtrees from databases of labeled rooted trees","volume":"17","author":[{"family":"Chi","given":"Yun"},{"family":"Xia","given":"Yi"},{"family":"Yang","given":"Yirong"},{"family":"Muntz","given":"Richard R."}],"issued":{"date-parts":[[2005]]}},
  {"id":"huanSpinMiningMaximal2004","type":"paper-conference","container-title":"Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining","page":"581–586","publisher":"ACM","source":"Google Scholar","title":"Spin: mining maximal frequent subgraphs from graph databases","title-short":"Spin","author":[{"family":"Huan","given":"Jun"},{"family":"Wang","given":"Wei"},{"family":"Prins","given":"Jan"},{"family":"Yang","given":"Jiong"}],"issued":{"date-parts":[[2004]]}},
  {"id":"jiangSurveyFrequentSubgraph2013","type":"article-journal","container-title":"The Knowledge Engineering Review","issue":"1","page":"75–105","source":"Google Scholar","title":"A survey of frequent subgraph mining algorithms","volume":"28","author":[{"family":"Jiang","given":"Chuntao"},{"family":"Coenen","given":"Frans"},{"family":"Zito","given":"Michele"}],"issued":{"date-parts":[[2013]]}},
  {"id":"offuttMutationTestingImplements2006","type":"paper-conference","container-title":"Second Workshop on Mutation Analysis (Mutation 2006-ISSRE Workshops 2006)","page":"12–12","publisher":"IEEE","source":"Google Scholar","title":"Mutation testing implements grammar-based testing","author":[{"family":"Offutt","given":"Jeff"},{"family":"Ammann","given":"Paul"},{"family":"Liu","given":"Lisa"}],"issued":{"date-parts":[[2006]]}},
  {"id":"vanderstormMultilingualProgrammingEnvironments2015","type":"article-journal","abstract":"Software projects consist of different kinds of artifacts: build files, configuration files, markup files, source code in different software languages, and so on. At the same time, however, most integrated development environments (IDEs) are focused on a single (programming) language. Even if a programming environment supports multiple languages (e.g., Eclipse), IDE features such as cross-referencing, refactoring, or debugging, do not often cross language boundaries. What would it mean for programming environment to be truly multilingual? In this short paper we sketch a vision of a system that integrates IDE support across language boundaries. We propose to build this system on a foundation of unified source code models and metaprogramming. Nevertheless, a number of important and hard research questions still need to be addressed.","collection-title":"Special Issue on New Ideas and Emerging Results in Understanding Software","container-title":"Science of Computer Programming","DOI":"10.1016/j.scico.2013.11.041","ISSN":"0167-6423","page":"143-149","source":"ScienceDirect","title":"Towards multilingual programming environments","URL":"http://www.sciencedirect.com/science/article/pii/S0167642313003341","volume":"97","author":[{"family":"Storm","given":"Tijs","non-dropping-particle":"van der"},{"family":"Vinju","given":"Jurgen J."}],"accessed":{"date-parts":[[2019,7,20]]},"issued":{"date-parts":[[2015,1,1]]},"container-title-short":"Science of Computer Programming"},
  {"id":"floresDetectionCrossLanguageSource2011","type":"chapter","abstract":"Internet has made available huge amounts of information, also source code. Source code repositories and, in general, programming related websites, facilitate its reuse. In this work, we propose a simple approach to the detection of cross-language source code reuse, a nearly investigated problem. Our preliminary experiments, based on character n-grams comparison, show that considering diﬀerent sections of the code (i.e., comments, code, reserved words, etc.), leads to diﬀerent results. When considering three programming languages: C++, Java, and Python, the best result is obtained when comments are discarded and the entire source code is considered.","container-title":"Natural Language Processing and Information Systems","ISBN":"978-3-642-22326-6 978-3-642-22327-3","language":"en","page":"250-253","publisher":"Springer Berlin Heidelberg","source":"DOI.org (Crossref)","title":"Towards the Detection of Cross-Language Source Code Reuse","URL":"http://link.springer.com/10.1007/978-3-642-22327-3_31","volume":"6716","editor":[{"family":"Muñoz","given":"Rafael"},{"family":"Montoyo","given":"Andrés"},{"family":"Métais","given":"Elisabeth"}],"author":[{"family":"Flores","given":"Enrique"},{"family":"Barrón-Cedeño","given":"Alberto"},{"family":"Rosso","given":"Paolo"},{"family":"Moreno","given":"Lidia"}],"accessed":{"date-parts":[[2019,7,22]]},"issued":{"date-parts":[[2011]]},"publisher-place":"Berlin, Heidelberg","DOI":"10.1007/978-3-642-22327-3_31"},
  {"id":"caraccioloPangeaWorkbenchStatically2014","type":"paper-conference","abstract":"Software corpora facilitate reproducibility of analyses, however, static analysis for an entire corpus still requires considerable effort, often duplicated unnecessarily by multiple users. Moreover, most corpora are designed for single languages increasing the effort for cross-language analysis. To address these aspects we propose Pangea, an infrastructure allowing fast development of static analyses on multi-language corpora. Pangea uses language-independent meta-models stored as object model snapshots that can be directly loaded into memory and queryed without any parsing overhead. To reduce the effort of performing static analyses, Pangea provides out-of-the box support for: creating and reﬁning analyses in a dedicated environment, deploying an analysis on an entire corpus, using a runner that supports parallel execution, and exporting results in various formats. In this tool demonstration we introduce Pangea and provide several usage scenarios that illustrate how it reduces the cost of analysis.","container-title":"2014 IEEE 14th International Working Conference on Source Code Analysis and Manipulation","DOI":"10.1109/SCAM.2014.39","event":"2014 IEEE 14th International Working Conference on Source Code Analysis and Manipulation (SCAM)","ISBN":"978-1-4799-6148-1","language":"en","page":"71-76","publisher":"IEEE","source":"DOI.org (Crossref)","title":"Pangea: A Workbench for Statically Analyzing Multi-language Software Corpora","title-short":"Pangea","URL":"http://ieeexplore.ieee.org/document/6975639/","author":[{"family":"Caracciolo","given":"Andrea"},{"family":"Chis","given":"Andrei"},{"family":"Spasojevic","given":"Boris"},{"family":"Lungu","given":"Mircea"}],"accessed":{"date-parts":[[2019,7,22]]},"issued":{"date-parts":[[2014,9]]},"publisher-place":"Victoria, BC, Canada"},
  {"id":"demeyerFAMIX1theFAMOOS2001","type":"article-journal","source":"ResearchGate","title":"FAMIX 2. 1-the FAMOOS information exchange model","author":[{"family":"Demeyer","given":"Serge"},{"family":"Tichelaar","given":"S"},{"family":"Ducasse","given":"Stéphane"}],"issued":{"date-parts":[[2001,1,1]]}},
  {"id":"janesHowCalculateSoftware2013","type":"chapter","abstract":"Source code metrics help to evaluate the quality of the code, for example, to detect the most complex parts of the program. When writing a system which calculates metrics, especially when it has to support multiple source code languages, the biggest problem which arises is the creation of parsers for each supported language. In this paper we suggest an unusual Open Source solution, that avoids creating such parsers from scratch. We suggest and explain how to use parsers contained in the Eclipse IDE as parsers that support contemporary language features, are actively maintained, can recover from errors, and provide not just the abstract syntax tree, but the whole type information of the source program. The ﬁndings described in this paper provide to practitioners a way to use Open Source parsers without the need to deal with parser generators, or to write a parser from scratch.","container-title":"Open Source Software: Quality Verification","ISBN":"978-3-642-38927-6 978-3-642-38928-3","language":"en","page":"264-270","publisher":"Springer Berlin Heidelberg","source":"DOI.org (Crossref)","title":"How to Calculate Software Metrics for Multiple Languages Using Open Source Parsers","URL":"http://link.springer.com/10.1007/978-3-642-38928-3_20","volume":"404","editor":[{"family":"Petrinja","given":"Etiel"},{"family":"Succi","given":"Giancarlo"},{"family":"El Ioini","given":"Nabil"},{"family":"Sillitti","given":"Alberto"}],"author":[{"family":"Janes","given":"Andrea"},{"family":"Piatov","given":"Danila"},{"family":"Sillitti","given":"Alberto"},{"family":"Succi","given":"Giancarlo"}],"accessed":{"date-parts":[[2019,7,22]]},"issued":{"date-parts":[[2013]]},"publisher-place":"Berlin, Heidelberg","DOI":"10.1007/978-3-642-38928-3_20"},
  {"id":"cormenIntroductionAlgorithms2001","type":"book","edition":"2nd","ISBN":"0-262-03293-7","publisher":"The MIT Press","title":"Introduction to Algorithms","author":[{"family":"Cormen","given":"Thomas H."},{"family":"Leiserson","given":"Charles E."},{"family":"Rivest","given":"Ronald L."},{"family":"Stein","given":"Clifford"}],"issued":{"date-parts":[[2001]]},"publisher-place":"Cambridge Massachusetts"},
  {"id":"chomskyCertainFormalProperties1959","type":"article-journal","abstract":"A grammar can be regarded as a device that enumerates the sentences of a language. We study a sequence of restrictions that limit grammars first to Turing machines, then to two types of system from which a phrase structure description of the generated language can be drawn, and finally to finite state Markov sources (finite automata). These restrictions are shown to be increasingly heavy in the sense that the languages that can be generated by grammars meeting a given restriction constitute a proper subset of those that can be generated by grammars meeting the preceding restriction. Various formulations of phrase structure description are considered, and the source of their excess generative power over finite state sources is investigated in greater detail.","container-title":"Information and Control","DOI":"10.1016/S0019-9958(59)90362-6","ISSN":"0019-9958","issue":"2","page":"137-167","source":"ScienceDirect","title":"On certain formal properties of grammars","URL":"http://www.sciencedirect.com/science/article/pii/S0019995859903626","volume":"2","author":[{"family":"Chomsky","given":"Noam"}],"accessed":{"date-parts":[[2019,7,31]]},"issued":{"date-parts":[[1959,6,1]]},"container-title-short":"Information and Control"},
  {"id":"AntlrGrammarsv4Grammars","type":"webpage","container-title":"Github","title":"antlr/grammars-v4: Grammars written for ANTLR v4; expectation that the grammars are free of actions.","URL":"https://github.com/antlr/grammars-v4","accessed":{"date-parts":[[2019,8,1]]}},
  {"id":"offuttMutationTestingImplements2006a","type":"paper-conference","abstract":"This paper presents an abstract view of mutation analysis. Mutation was originally thought of as making changes to program source, but similar kinds of changes have been applied to other artifacts, including program specifications, XML, and input languages. This paper argues that mutation analysis is actually a way to modify any software artifact based on its syntactic description, and is in the same family of test generation methods that create inputs from syntactic descriptions. The essential characteristic of mutation is that a syntactic description such as a grammar is used to create tests. We call this abstract view grammar-based testing, and view it as an interface, which mutation analysis implements. This shift in view allows mutation to be defined in a general way, yielding three benefits. First, it provides a simpler way to understand mutation. Second, it makes it easier to develop future applications of mutation analysis, such as finite state machines and use case collaboration diagrams. The third benefit, which due to space limitations is not explored in this paper, is ensuring that existing techniques are complete according to the criteria defined here.","container-title":"Second Workshop on Mutation Analysis (Mutation 2006 - ISSRE Workshops 2006)","DOI":"10.1109/MUTATION.2006.11","event":"Second Workshop on Mutation Analysis (Mutation 2006 - ISSRE Workshops 2006)","page":"12-12","source":"IEEE Xplore","title":"Mutation testing implements grammar-based testing","author":[{"family":"Offutt","given":"J."},{"family":"Ammann","given":"P."},{"family":"Liu","given":"L."}],"issued":{"date-parts":[[2006,11]]}},
  {"id":"friedmanUseRanksAvoid1937","type":"article-journal","container-title":"Journal of the American Statistical Association","DOI":"10.1080/01621459.1937.10503522","ISSN":"0162-1459, 1537-274X","issue":"200","language":"en","page":"675-701","source":"DOI.org (Crossref)","title":"The use of ranks to avoid the assumption of normality implicit in the analysis of variance","URL":"http://www.tandfonline.com/doi/abs/10.1080/01621459.1937.10503522","volume":"32","author":[{"family":"Friedman","given":"Milton"}],"accessed":{"date-parts":[[2019,8,6]]},"issued":{"date-parts":[[1937,12]]},"container-title-short":"Journal of the American Statistical Association"},
  {"id":"steelRankSumTest1960","type":"article-journal","container-title":"Technometrics","DOI":"10.1080/00401706.1960.10489894","ISSN":"0040-1706, 1537-2723","issue":"2","language":"en","page":"197-207","source":"CrossRef","title":"A Rank Sum Test for Comparing All Pairs of Treatments","URL":"http://www.tandfonline.com/doi/abs/10.1080/00401706.1960.10489894","volume":"2","author":[{"family":"Steel","given":"Robert G. D."}],"accessed":{"date-parts":[[2014,11,11]]},"issued":{"date-parts":[[1960,5]]}},
  {"id":"steelMultipleComparisonSign1959","type":"article-journal","container-title":"Journal of the American Statistical Association","DOI":"10.2307/2282500","ISSN":"01621459","issue":"288","page":"767","source":"CrossRef","title":"A Multiple Comparison Sign Test: Treatments Versus Control","title-short":"A Multiple Comparison Sign Test","URL":"http://www.jstor.org/stable/2282500?origin=crossref","volume":"54","author":[{"family":"Steel","given":"Robert G. D."}],"accessed":{"date-parts":[[2014,12,1]]},"issued":{"date-parts":[[1959,12]]}},
  {"id":"dunnettMultipleComparisonProcedure1955","type":"article-journal","container-title":"Journal of the American Statistical Association","DOI":"10.1080/01621459.1955.10501294","ISSN":"0162-1459, 1537-274X","issue":"272","language":"en","page":"1096-1121","source":"CrossRef","title":"A Multiple Comparison Procedure for Comparing Several Treatments with a Control","URL":"http://www.tandfonline.com/doi/abs/10.1080/01621459.1955.10501294","volume":"50","author":[{"family":"Dunnett","given":"Charles W."}],"accessed":{"date-parts":[[2014,10,29]]},"issued":{"date-parts":[[1955,12]]}},
  {"id":"boxAnalysisTransformations1964","type":"article-journal","abstract":"In the analysis of data it is often assumed that observations y<sub>1</sub>, y<sub>2</sub>, ..., y<sub>n</sub> are independently normally distributed with constant variance and with expectations specified by a model linear in a set of parameters θ. In this paper we make the less restrictive assumption that such a normal, homoscedastic, linear model is appropriate after some suitable transformation has been applied to the y's. Inferences about the transformation and about the parameters of the linear model are made by computing the likelihood function and the relevant posterior distribution. The contributions of normality, homoscedasticity and additivity to the transformation are separated. The relation of the present methods to earlier procedures for finding transformations is discussed. The methods are illustrated with examples.","container-title":"Journal of the Royal Statistical Society. Series B (Methodological)","ISSN":"00359246","issue":"2","language":"English","page":"pp. 211-252","title":"An Analysis of Transformations","URL":"http://www.jstor.org/stable/2984418","volume":"26","author":[{"family":"Box","given":"G. E. P."},{"family":"Cox","given":"D. R."}],"issued":{"date-parts":[[1964]]}},
  {"id":"steelMultipleComparisonRank1959","type":"article-journal","container-title":"Biometrics","DOI":"10.2307/2527654","ISSN":"0006341X","issue":"4","page":"560","source":"CrossRef","title":"A multiple comparison rank sum test: Treatments versus control","title-short":"A Multiple Comparison Rank Sum Test","URL":"http://www.jstor.org/stable/2527654?origin=crossref","volume":"15","author":[{"family":"Steel","given":"Robert G. D."}],"accessed":{"date-parts":[[2014,10,29]]},"issued":{"date-parts":[[1959,12]]}},
  {"id":"rhyneTablesTreatmentsControl1965","type":"article-journal","container-title":"Technometrics","DOI":"10.2307/1266590","ISSN":"00401706","issue":"3","page":"293","source":"CrossRef","title":"Tables for a Treatments versus Control Multiple Comparisons Sign Test","URL":"http://www.jstor.org/stable/1266590?origin=crossref","volume":"7","author":[{"family":"Rhyne","given":"A. L."},{"family":"Steel","given":"R. G. D."}],"accessed":{"date-parts":[[2014,12,1]]},"issued":{"date-parts":[[1965,8]]}},
  {"id":"leveneRobustTestsEquality1960","type":"article-journal","container-title":"Contributions to Probability and Statistics: Essays in Honor of Harold Hotelling","page":"278–292","title":"Robust tests for equality of variances","volume":"2","author":[{"family":"Levene","given":"Howard"}],"issued":{"date-parts":[[1960]]}},
  {"id":"heeringSyntaxDefinitionFormalism1989","type":"article-journal","container-title":"ACM SIGPLAN Notices","DOI":"10.1145/71605.71607","ISSN":"03621340","issue":"11","language":"en","page":"43-75","source":"DOI.org (Crossref)","title":"The syntax definition formalism SDF---reference manual---","URL":"http://portal.acm.org/citation.cfm?doid=71605.71607","volume":"24","author":[{"family":"Heering","given":"J."},{"family":"Hendriks","given":"P. R. H."},{"family":"Klint","given":"P."},{"family":"Rekers","given":"J."}],"accessed":{"date-parts":[[2019,7,9]]},"issued":{"date-parts":[[1989,11,1]]},"container-title-short":"SIGPLAN Not."},
  {"id":"colesPITPracticalMutation2016","type":"paper-conference","container-title":"Proceedings of the 25th International Symposium on Software Testing and Analysis - ISSTA 2016","DOI":"10.1145/2931037.2948707","event":"the 25th International Symposium","ISBN":"978-1-4503-4390-9","language":"en","page":"449-452","publisher":"ACM Press","source":"DOI.org (Crossref)","title":"PIT: a practical mutation testing tool for Java (demo)","title-short":"PIT","URL":"http://dl.acm.org/citation.cfm?doid=2931037.2948707","author":[{"family":"Coles","given":"Henry"},{"family":"Laurent","given":"Thomas"},{"family":"Henard","given":"Christopher"},{"family":"Papadakis","given":"Mike"},{"family":"Ventresque","given":"Anthony"}],"accessed":{"date-parts":[[2019,8,6]]},"issued":{"date-parts":[[2016]]},"publisher-place":"Saarbr&#252;cken, Germany"},
  {"id":"caldieraGoalQuestionMetric1994","type":"article-journal","container-title":"Encyclopedia of software engineering","page":"528–532","title":"The goal question metric approach","author":[{"family":"Caldiera","given":"Victor R Basili1 Gianluigi"},{"family":"Rombach","given":"H Dieter"}],"issued":{"date-parts":[[1994]]}},
  {"id":"basiliSoftwareModelingMeasurement1992","type":"report","publisher":"University of Maryland at College Park","title":"Software Modeling and Measurement: The Goal/Question/Metric Paradigm","author":[{"family":"Basili","given":"Victor R."}],"issued":{"date-parts":[[1992]]},"publisher-place":"College Park, MD, USA"},
  {"id":"kruskalUseRanksOneCriterion1952","type":"article-journal","container-title":"Journal of the American Statistical Association","DOI":"10.1080/01621459.1952.10483441","ISSN":"0162-1459, 1537-274X","issue":"260","language":"en","page":"583-621","source":"DOI.org (Crossref)","title":"Use of Ranks in One-Criterion Variance Analysis","URL":"http://www.tandfonline.com/doi/abs/10.1080/01621459.1952.10483441","volume":"47","author":[{"family":"Kruskal","given":"William H."},{"family":"Wallis","given":"W. Allen"}],"accessed":{"date-parts":[[2019,8,5]]},"issued":{"date-parts":[[1952,12]]},"container-title-short":"Journal of the American Statistical Association"},
  {"id":"parrDefinitiveANTLRReference2012","type":"book","call-number":"QA76.7 .P37 2012","collection-title":"The pragmatic programmers","ISBN":"978-1-934356-99-9","note":"OCLC: ocn802295434","number-of-pages":"305","publisher":"The Pragmatic Bookshelf","source":"Library of Congress ISBN","title":"The definitive ANTLR 4 reference","author":[{"family":"Parr","given":"Terence"}],"issued":{"date-parts":[[2012]]},"publisher-place":"Dallas, Texas"},
  {"id":"runesonCaseStudyResearch2012","type":"book","call-number":"QA76.76.D47 C37 2012","ISBN":"978-1-118-10435-4","number-of-pages":"237","publisher":"Wiley","source":"Library of Congress ISBN","title":"Case study research in software engineering: guidelines and examples","title-short":"Case study research in software engineering","editor":[{"family":"Runeson","given":"Per"}],"issued":{"date-parts":[[2012]]},"publisher-place":"Hoboken, N.J"},
  {"id":"yinCaseStudyResearch2009","type":"book","call-number":"H62 .Y56 2009","collection-number":"v. 5","collection-title":"Applied social research methods","edition":"4th ed","ISBN":"978-1-4129-6099-1","number-of-pages":"219","publisher":"Sage Publications","source":"Library of Congress ISBN","title":"Case study research: design and methods","title-short":"Case study research","author":[{"family":"Yin","given":"Robert K."}],"issued":{"date-parts":[[2009]]},"publisher-place":"Los Angeles, Calif"},
  {"id":"cordyTXLRapidPrototyping1991","type":"article-journal","container-title":"Computer Languages","DOI":"10.1016/0096-0551(91)90019-6","ISSN":"00960551","issue":"1","language":"en","page":"97-107","source":"DOI.org (Crossref)","title":"TXL: A rapid prototyping system for programming language dialects","title-short":"TXL","URL":"https://linkinghub.elsevier.com/retrieve/pii/0096055191900196","volume":"16","author":[{"family":"Cordy","given":"James R."},{"family":"Halpern-Hamu","given":"Charles D."},{"family":"Promislow","given":"Eric"}],"accessed":{"date-parts":[[2019,7,9]]},"issued":{"date-parts":[[1991,1]]},"container-title-short":"Computer Languages"},
  {"id":"campbellQuasiexperimentationDesignAnalysis1979","type":"book","publisher":"Houghton Mifflin Company","title":"Quasi-experimentation: Design and Analysis Issues for Field Settings","author":[{"family":"Campbell","given":"D."},{"family":"Cook","given":"T. D."}],"issued":{"date-parts":[[1979]]}},
  {"id":"zaytsevGrammarZooCorpus2015","type":"article-journal","container-title":"Science of Computer Programming","DOI":"10.1016/j.scico.2014.07.010","ISSN":"01676423","language":"en","page":"28-51","source":"DOI.org (Crossref)","title":"Grammar Zoo: A corpus of experimental grammarware","title-short":"Grammar Zoo","URL":"https://linkinghub.elsevier.com/retrieve/pii/S0167642314003347","volume":"98","author":[{"family":"Zaytsev","given":"Vadim"}],"accessed":{"date-parts":[[2019,7,7]]},"issued":{"date-parts":[[2015,2]]},"container-title-short":"Science of Computer Programming"},
  {"id":"deanGrammarProgrammingTXL2002","type":"paper-conference","container-title":"Proceedings. Second IEEE International Workshop on Source Code Analysis and Manipulation","DOI":"10.1109/SCAM.2002.1134109","event":"Second IEEE International Workshop on Source Code Analysis and Manipulation","ISBN":"978-0-7695-1793-3","page":"93-102","publisher":"IEEE Comput. Soc","source":"DOI.org (Crossref)","title":"Grammar programming in TXL","URL":"http://ieeexplore.ieee.org/document/1134109/","author":[{"family":"Dean","given":"T.R."},{"family":"Cordy","given":"J.R."},{"family":"Malton","given":"A.J."},{"family":"Schneider","given":"K.A."}],"accessed":{"date-parts":[[2019,7,7]]},"issued":{"date-parts":[[2002]]},"publisher-place":"Montreal, Que., Canada"},
  {"id":"campbellExperimentalQuasiexperimentalDesigns1963","type":"book","publisher":"Rand-McNally","title":"Experimental and Quasi-experimental Designs for Research","author":[{"family":"Campbell","given":"D."},{"family":"Stanley","given":"J."}],"issued":{"date-parts":[[1963]]}},
  {"id":"montgomeryDesignAnalysisExperiments2013","type":"book","call-number":"QA279 .M66 2013","edition":"Eighth edition","ISBN":"978-1-118-14692-7","number-of-pages":"730","publisher":"John Wiley & Sons, Inc","source":"Library of Congress ISBN","title":"Design and analysis of experiments","author":[{"family":"Montgomery","given":"Douglas C."}],"issued":{"date-parts":[[2013]]},"publisher-place":"Hoboken, NJ"},
  {"id":"csuhaj-varjuDescriptionalComplexityContextfree1993","type":"article-journal","container-title":"Theoretical Computer Science","DOI":"10.1016/0304-3975(93)90021-K","ISSN":"03043975","issue":"2","language":"en","page":"277-289","source":"DOI.org (Crossref)","title":"Descriptional complexity of context-free grammar forms","URL":"https://linkinghub.elsevier.com/retrieve/pii/030439759390021K","volume":"112","author":[{"family":"Csuhaj-Varjú","given":"Erzsébet"},{"family":"Kelemenová","given":"Alica"}],"accessed":{"date-parts":[[2019,7,7]]},"issued":{"date-parts":[[1993,5]]},"container-title-short":"Theoretical Computer Science"},
  {"id":"vandenbrandCurrentParsingTechniques1998","type":"paper-conference","container-title":"Proceedings. 6th International Workshop on Program Comprehension. IWPC'98 (Cat. No.98TB100242)","DOI":"10.1109/WPC.1998.693325","event":"6th International Workshop on Program Comprehension. IWPC'98","ISBN":"978-0-8186-8560-6","page":"108-117","publisher":"IEEE Comput. Soc","source":"DOI.org (Crossref)","title":"Current parsing techniques in software renovation considered harmful","URL":"http://ieeexplore.ieee.org/document/693325/","author":[{"family":"Brand","given":"M.","non-dropping-particle":"van den"},{"family":"Sellink","given":"A."},{"family":"Verhoef","given":"C."}],"accessed":{"date-parts":[[2019,7,7]]},"issued":{"date-parts":[[1998]]},"publisher-place":"Ischia, Italy"},
  {"id":"shapiroAnalysisVarianceTest1965","type":"article-journal","container-title":"Biometrika","DOI":"10.2307/2333709","ISSN":"00063444","issue":"3/4","page":"591","source":"CrossRef","title":"An Analysis of Variance Test for Normality (Complete Samples)","URL":"http://www.jstor.org/stable/2333709?origin=crossref","volume":"52","author":[{"family":"Shapiro","given":"S. S."},{"family":"Wilk","given":"M. B."}],"accessed":{"date-parts":[[2014,10,29]]},"issued":{"date-parts":[[1965,12]]}},
  {"id":"cordyTXLLanguageProgramming2004","type":"article-journal","container-title":"Electronic Notes in Theoretical Computer Science","DOI":"10.1016/j.entcs.2004.11.006","ISSN":"15710661","language":"en","page":"3-31","source":"DOI.org (Crossref)","title":"TXL - A Language for Programming Language Tools and Applications","URL":"https://linkinghub.elsevier.com/retrieve/pii/S157106610405217X","volume":"110","author":[{"family":"Cordy","given":"James R."}],"accessed":{"date-parts":[[2019,7,7]]},"issued":{"date-parts":[[2004,12]]},"container-title-short":"Electronic Notes in Theoretical Computer Science"},
  {"id":"ansariRankSumTestsDispersions1960","type":"article-journal","container-title":"The Annals of Mathematical Statistics","DOI":"10.1214/aoms/1177705688","ISSN":"0003-4851","issue":"4","language":"en","page":"1174-1189","source":"CrossRef","title":"Rank-Sum Tests for Dispersions","URL":"http://projecteuclid.org/euclid.aoms/1177705688","volume":"31","author":[{"family":"Ansari","given":"A. R."},{"family":"Bradley","given":"R. A."}],"accessed":{"date-parts":[[2014,11,11]]},"issued":{"date-parts":[[1960,12]]}},
  {"id":"andersonDistributionTwoSampleCramervon1962","type":"article-journal","container-title":"The Annals of Mathematical Statistics","DOI":"10.1214/aoms/1177704477","ISSN":"0003-4851","issue":"3","language":"en","page":"1148-1159","source":"CrossRef","title":"On the Distribution of the Two-Sample Cramer-von Mises Criterion","URL":"http://projecteuclid.org/euclid.aoms/1177704477","volume":"33","author":[{"family":"Anderson","given":"T. W."}],"accessed":{"date-parts":[[2014,11,11]]},"issued":{"date-parts":[[1962,9]]}},
  {"id":"alvesMetricationSDFGrammars2005","type":"article-journal","container-title":"Dept. de Informática da Univ. do Minho Campus de Gualtar, Braga, Portugal. Rep. Tec. DI-PURe-05.05","title":"Metrication of SDF grammars","volume":"1","author":[{"family":"Alves","given":"Tiago"},{"family":"Visser","given":"Joost"}],"issued":{"date-parts":[[2005]]}},
  {"id":"wohlinExperimentationSoftwareEngineering2012","type":"book","ISBN":"978-3-642-29043-5 978-3-642-29044-2","language":"en","publisher":"Springer Berlin Heidelberg","source":"CrossRef","title":"Experimentation in Software Engineering","URL":"http://link.springer.com/10.1007/978-3-642-29044-2","author":[{"family":"Wohlin","given":"Claes"},{"family":"Runeson","given":"Per"},{"family":"Höst","given":"Martin"},{"family":"Ohlsson","given":"Magnus C."},{"family":"Regnell","given":"Björn"},{"family":"Wesslén","given":"Anders"}],"accessed":{"date-parts":[[2014,6,22]]},"issued":{"date-parts":[[2012]]},"publisher-place":"Berlin, Heidelberg"},
  {"id":"tukeyComparingIndividualMeans1949","type":"article-journal","container-title":"Biometrics","DOI":"10.2307/3001913","ISSN":"0006341X","issue":"2","page":"99","source":"CrossRef","title":"Comparing Individual Means in the Analysis of Variance","URL":"http://www.jstor.org/stable/3001913?origin=crossref","volume":"5","author":[{"family":"Tukey","given":"John W."}],"accessed":{"date-parts":[[2015,9,18]]},"issued":{"date-parts":[[1949,6]]}},
  {"id":"andersonTestGoodnessFit1954","type":"article-journal","container-title":"Journal of the American Statistical Association","DOI":"10.2307/2281537","ISSN":"01621459","issue":"268","page":"765","source":"CrossRef","title":"A test of goodness of fit","URL":"http://www.jstor.org/stable/2281537?origin=crossref","volume":"49","author":[{"family":"Anderson","given":"T. W."},{"family":"Darling","given":"D. A."}],"accessed":{"date-parts":[[2014,11,11]]},"issued":{"date-parts":[[1954,12]]}},
  {"id":"kendallNewMeasureRank1938","type":"article-journal","container-title":"Biometrika","DOI":"10.2307/2332226","ISSN":"00063444","issue":"1/2","page":"81","source":"CrossRef","title":"A New Measure of Rank Correlation","URL":"http://www.jstor.org/stable/2332226?origin=crossref","volume":"30","author":[{"family":"Kendall","given":"M. G."}],"accessed":{"date-parts":[[2014,6,25]]},"issued":{"date-parts":[[1938,6]]}},
  {"id":"powerMetricsSuiteGrammarbased2004","type":"article-journal","container-title":"Journal of Software Maintenance and Evolution: Research and Practice","DOI":"10.1002/smr.293","ISSN":"1532-060X, 1532-0618","issue":"6","language":"en","page":"405-426","source":"DOI.org (Crossref)","title":"A metrics suite for grammar-based software","URL":"http://doi.wiley.com/10.1002/smr.293","volume":"16","author":[{"family":"Power","given":"James F."},{"family":"Malloy","given":"Brian A."}],"accessed":{"date-parts":[[2019,7,7]]},"issued":{"date-parts":[[2004,11]]},"container-title-short":"J. Softw. Maint. Evol.: Res. Pract."},
  {"id":"lanzaObjectorientedMetricsPractice2011","type":"book","ISBN":"978-3-642-06374-9","language":"English","note":"OCLC: 750954916","publisher":"Springer","source":"Open WorldCat","title":"Object-oriented metrics in practice: using software metrics to characterize, evaluate, and improve the design of object-oriented systems","title-short":"Object-oriented metrics in practice","author":[{"family":"Lanza","given":"Michele"},{"family":"Marinescu","given":"Radu"}],"issued":{"date-parts":[[2011]]},"publisher-place":"Berlin; London"},
  {"id":"rosenkrantzMatrixEquationsNormal1967","type":"article-journal","abstract":"The relationship between the set of productions of a context-free grammar and the corresponding set of defining equations is first pointed out. The closure operation on a matrix of strings is defined and this concept is used to formalize the solution to a set of linear equations. A procedure is then given for rewriting a context-free grammar in Greibach normal form, where the replacements string of each production begins with a terminal symbol. An additional procedure is given for rewriting the grammar so that each replacement string both begins and ends with a terminal symbol. Neither procedure requires the evaluation of regular begins and ends with a terminal symbol. Neither procedure requires the evaluation of regular expressions over the total vocabulary of the grammar, as is required by Greibach's procedure.","container-title":"J. ACM","DOI":"10.1145/321406.321412","ISSN":"0004-5411","issue":"3","page":"501–507","source":"ACM Digital Library","title":"Matrix Equations and Normal Forms for Context-Free Grammars","URL":"http://doi.acm.org/10.1145/321406.321412","volume":"14","author":[{"family":"Rosenkrantz","given":"Daniel J."}],"accessed":{"date-parts":[[2019,9,25]]},"issued":{"date-parts":[[1967,7]]}},
  {"id":"higginsIntroductionModernNonparametric2004","type":"book","call-number":"QA278.8 .H54 2004","ISBN":"978-0-534-38775-4","number-of-pages":"366","publisher":"Brooks/Cole","source":"Library of Congress ISBN","title":"An introduction to modern nonparametric statistics","author":[{"family":"Higgins","given":"James J."}],"issued":{"date-parts":[[2004]]},"publisher-place":"Pacific Grove, CA"},
  {"id":"jonckheereDistributionFreeKSampleTest1954","type":"article-journal","container-title":"Biometrika","DOI":"10.2307/2333011","ISSN":"00063444","issue":"1/2","page":"133","source":"DOI.org (Crossref)","title":"A Distribution-Free k-Sample Test Against Ordered Alternatives","URL":"https://www.jstor.org/stable/2333011?origin=crossref","volume":"41","author":[{"family":"Jonckheere","given":"A. R."}],"accessed":{"date-parts":[[2019,9,30]]},"issued":{"date-parts":[[1954,6]]},"container-title-short":"Biometrika"},
  {"id":"binkleySourceCodeAnalysis2007","type":"paper-conference","abstract":"The automated and semi-automated analysis of source code has remained a topic of intense research for more than thirty years. During this period, algorithms and techniques for source-code analysis have changed, sometimes dramatically. The abilities of the tools that implement them have also expanded to meet new and diverse challenges. This paper surveys current work on source-code analysis. It also provides a road map for future work over the next ﬁve-year period and speculates on the development of source-code analysis applications, techniques, and challenges over the next 10, 20, and 50 years.","container-title":"Future of Software Engineering (FOSE '07)","DOI":"10.1109/FOSE.2007.27","event":"Future of Software Engineering","ISBN":"978-0-7695-2829-8","language":"en","page":"104-119","publisher":"IEEE","source":"DOI.org (Crossref)","title":"Source Code Analysis: A Road Map","title-short":"Source Code Analysis","URL":"http://ieeexplore.ieee.org/document/4221615/","author":[{"family":"Binkley","given":"David"}],"accessed":{"date-parts":[[2019,12,6]]},"issued":{"date-parts":[[2007,5]]},"publisher-place":"Minneapolis, MN, USA"},
  {"id":"kirkovSourceCodeAnalysis","type":"article-journal","abstract":"In recent years the need of automatically source-code analysis tools has rapidly grown because of the significant increase of both the amount of the software programs and the program complexity. The present paper describes the main structure, algorithms and techniques implemented in some of the most popular tools for source-code analysis as well as an experimental comparison of such tools. The analysis process as well as a functionality of one of the tools is illustrated by an example of analyzing a sample program Finally some trends for development on modern source-code analysis systems are discussed.","language":"en","page":"19","source":"Zotero","title":"Source Code Analysis – An Overview","author":[{"family":"Kirkov","given":"Radoslav"},{"family":"Agre","given":"Gennady"}]},
  {"id":"linosMetricsToolMultilanguage","type":"article-journal","abstract":"In this paper, we present a prototype tool that automates the process of detecting, gathering and visualizing multi-language software metrics at an intermediate-language level. More specifically, the current version of our tool focuses on code written using the Microsoft Visual Studio .NET software development environment. It facilitates the process of locating and extracting software metrics found at the MSIL (Microsoft Intermediate Language) level. We illustrate the basic functionality of our tool and we discuss a preliminary case study performed in order to verify its functionality and validate its usefulness. Based on the results of this study, we continue improving the tool.","language":"en","page":"10","source":"Zotero","title":"A Metrics Tool for Multi-language Software","author":[{"family":"Linos","given":"Panos"},{"family":"Lucas","given":"Whitney"},{"family":"Myers","given":"Sig"},{"family":"Maier","given":"Ezekiel"}]},
  {"id":"clarkeExperimentingMutationTesting2016","type":"webpage","abstract":"The most common approach to measuring how comprehensive your unit tests are is to look at “code coverage”, literally the number of lines of…","container-title":"Medium","language":"en","title":"Experimenting with “mutation testing” and Kotlin","URL":"https://medium.com/@s4n1ty/experimenting-with-mutation-testing-and-kotlin-b515d77e85b5","author":[{"family":"Clarke","given":"Ian"}],"accessed":{"date-parts":[[2019,12,6]]},"issued":{"date-parts":[[2016,10,18]]}}
]
